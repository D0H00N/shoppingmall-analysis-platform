{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e47252d733994df58cd8b40232610faa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f5a4d2b84d04619aaf582e459c97094","IPY_MODEL_07f667cdf9334edf979ab0fc3f39db35","IPY_MODEL_7579d8863e1946849654c07dbab92cb4"],"layout":"IPY_MODEL_4e93e1328df74294a4c57891c3f41ab9"}},"3f5a4d2b84d04619aaf582e459c97094":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_659844ca12ce42dfa72ab035eb9028b6","placeholder":"​","style":"IPY_MODEL_88298ba54676402a8f68d3be9554920f","value":"tokenizer_config.json: 100%"}},"07f667cdf9334edf979ab0fc3f39db35":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0ca55bce9e942ffa3d0aa629bdfefe5","max":289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_548b715d66744163b9b2e4e271db5599","value":289}},"7579d8863e1946849654c07dbab92cb4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a104fe8194db4050ad1e222c441470a2","placeholder":"​","style":"IPY_MODEL_9bd3cbb60f7b42499f720304cea6f792","value":" 289/289 [00:00&lt;00:00, 7.42kB/s]"}},"4e93e1328df74294a4c57891c3f41ab9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"659844ca12ce42dfa72ab035eb9028b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88298ba54676402a8f68d3be9554920f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0ca55bce9e942ffa3d0aa629bdfefe5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"548b715d66744163b9b2e4e271db5599":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a104fe8194db4050ad1e222c441470a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bd3cbb60f7b42499f720304cea6f792":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d99ac6eabc044e4a0de917ded2f76f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_67b5feaafa21498aab900411317762b7","IPY_MODEL_99a43091fea64c709ca8d4ab2b1198cd","IPY_MODEL_40cd7f5d54eb46c587d8761e8dc6153f"],"layout":"IPY_MODEL_7a2d8abd987644178e3a93b601413df4"}},"67b5feaafa21498aab900411317762b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31d755485e954bf9bdfe7ff80f5cb179","placeholder":"​","style":"IPY_MODEL_858057f814554c9dba528d2cfa95cd72","value":"vocab.txt: 100%"}},"99a43091fea64c709ca8d4ab2b1198cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e55f76e9ec64864a0c91294783359c1","max":248477,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8851f4eab4c54a02812b5519dd67ee53","value":248477}},"40cd7f5d54eb46c587d8761e8dc6153f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a3f378651194701a3390a5298c61d8d","placeholder":"​","style":"IPY_MODEL_45c4e5fed4874ec99ecbe858c905dd61","value":" 248k/248k [00:00&lt;00:00, 1.98MB/s]"}},"7a2d8abd987644178e3a93b601413df4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31d755485e954bf9bdfe7ff80f5cb179":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"858057f814554c9dba528d2cfa95cd72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e55f76e9ec64864a0c91294783359c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8851f4eab4c54a02812b5519dd67ee53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a3f378651194701a3390a5298c61d8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45c4e5fed4874ec99ecbe858c905dd61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db4107ac08d14d01883072f585b886b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f9c80ab90de437d878115ba700a048b","IPY_MODEL_7e1ab27df68a4615b4c11b66186fb839","IPY_MODEL_3e01ef3deb8a41a88fa46094067ac6cc"],"layout":"IPY_MODEL_a01a6fef6d2b4272a962d79ee483f61e"}},"3f9c80ab90de437d878115ba700a048b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89eb5bb1577a49c08a4a10f8f9439e00","placeholder":"​","style":"IPY_MODEL_b16b8b2206f142c88c016a6d52da1822","value":"special_tokens_map.json: 100%"}},"7e1ab27df68a4615b4c11b66186fb839":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d418df60ced84a43843aaa1ac450a6d2","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24006f00bd944dd1ae22b2eb836dc190","value":125}},"3e01ef3deb8a41a88fa46094067ac6cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_018c50296f154665a2d58ec9d5c21045","placeholder":"​","style":"IPY_MODEL_a4dbb9cc9c3042268704653eb1eee0bc","value":" 125/125 [00:00&lt;00:00, 11.6kB/s]"}},"a01a6fef6d2b4272a962d79ee483f61e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89eb5bb1577a49c08a4a10f8f9439e00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b16b8b2206f142c88c016a6d52da1822":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d418df60ced84a43843aaa1ac450a6d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24006f00bd944dd1ae22b2eb836dc190":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"018c50296f154665a2d58ec9d5c21045":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4dbb9cc9c3042268704653eb1eee0bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c272bed92616443ba27ef521aee6228f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e128f553472486faab8ec77c15aade6","IPY_MODEL_2978854c12ca4378b3a6655051f4b38e","IPY_MODEL_e94a5335bb8642a7af4fc25db6f2aa04"],"layout":"IPY_MODEL_6b020b0dba054042a990aa453b1c87ad"}},"6e128f553472486faab8ec77c15aade6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_697de302ab7e47e59e250b971b6dfbfd","placeholder":"​","style":"IPY_MODEL_81878c1346b84a06a5bee2314a118dff","value":"tokenizer.json: 100%"}},"2978854c12ca4378b3a6655051f4b38e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_70047a3c385d4c1db145bd7246424e17","max":494860,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e250ed62fa21442180ac04024072403b","value":494860}},"e94a5335bb8642a7af4fc25db6f2aa04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_983ea317ecd6458593e58793cc548d98","placeholder":"​","style":"IPY_MODEL_869683a2ca9f4ca39d1d48fc7c2f9adf","value":" 495k/495k [00:00&lt;00:00, 3.98MB/s]"}},"6b020b0dba054042a990aa453b1c87ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"697de302ab7e47e59e250b971b6dfbfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81878c1346b84a06a5bee2314a118dff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70047a3c385d4c1db145bd7246424e17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e250ed62fa21442180ac04024072403b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"983ea317ecd6458593e58793cc548d98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869683a2ca9f4ca39d1d48fc7c2f9adf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5abd62683ce4c43a945202668587dc8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_835dd391a13a4608a9b281499f196948","IPY_MODEL_32f34afe66f448448cb61f1e02587350","IPY_MODEL_058a543eec3a43afb5e59dbbab792120"],"layout":"IPY_MODEL_68496234f5804e0687e52562d0bff392"}},"835dd391a13a4608a9b281499f196948":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ef8bb4794fd487f8688f94b80be1b15","placeholder":"​","style":"IPY_MODEL_018e1ff78a524933994de3683dc6dfbc","value":"config.json: 100%"}},"32f34afe66f448448cb61f1e02587350":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44b912a74f0b4e478d58da45529cd483","max":425,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7268c01eef21467897c1818354c937ee","value":425}},"058a543eec3a43afb5e59dbbab792120":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7117467a8ea54e0e8805c210e0b38685","placeholder":"​","style":"IPY_MODEL_054af28dfe584497b589393f48a1811a","value":" 425/425 [00:00&lt;00:00, 29.0kB/s]"}},"68496234f5804e0687e52562d0bff392":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ef8bb4794fd487f8688f94b80be1b15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"018e1ff78a524933994de3683dc6dfbc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44b912a74f0b4e478d58da45529cd483":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7268c01eef21467897c1818354c937ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7117467a8ea54e0e8805c210e0b38685":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"054af28dfe584497b589393f48a1811a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["# 모델 돌린 코드\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pandas as pd\n","import numpy as np\n","from transformers import BertTokenizer, BertForSequenceClassification, get_scheduler\n","from torch.utils.data import DataLoader, random_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, accuracy_score\n","from transformers import logging\n","\n","# 불필요한 경고 메시지 숨기기\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","logging.set_verbosity_error()\n"],"metadata":{"id":"8orL1qWc2jeD","executionInfo":{"status":"ok","timestamp":1740533077441,"user_tz":-540,"elapsed":24414,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["\n","# GPU 설정 및 최적화\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.backends.cudnn.benchmark = True  # 연산 최적화 활성화\n","print(f\"Using device: {device}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-RbODIo2sos","executionInfo":{"status":"ok","timestamp":1740533092752,"user_tz":-540,"elapsed":104,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"a1a8ff7b-da78-4b53-aea2-e61457897d6d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","GPU: Tesla T4\n"]}]},{"cell_type":"code","source":["# 데이터 로드\n","df_resampled = pd.read_csv(\"./review_balanced_resampled.csv\")\n","\n","# BERT 토크나이저 로드\n","tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295,"referenced_widgets":["e47252d733994df58cd8b40232610faa","3f5a4d2b84d04619aaf582e459c97094","07f667cdf9334edf979ab0fc3f39db35","7579d8863e1946849654c07dbab92cb4","4e93e1328df74294a4c57891c3f41ab9","659844ca12ce42dfa72ab035eb9028b6","88298ba54676402a8f68d3be9554920f","e0ca55bce9e942ffa3d0aa629bdfefe5","548b715d66744163b9b2e4e271db5599","a104fe8194db4050ad1e222c441470a2","9bd3cbb60f7b42499f720304cea6f792","4d99ac6eabc044e4a0de917ded2f76f5","67b5feaafa21498aab900411317762b7","99a43091fea64c709ca8d4ab2b1198cd","40cd7f5d54eb46c587d8761e8dc6153f","7a2d8abd987644178e3a93b601413df4","31d755485e954bf9bdfe7ff80f5cb179","858057f814554c9dba528d2cfa95cd72","1e55f76e9ec64864a0c91294783359c1","8851f4eab4c54a02812b5519dd67ee53","1a3f378651194701a3390a5298c61d8d","45c4e5fed4874ec99ecbe858c905dd61","db4107ac08d14d01883072f585b886b4","3f9c80ab90de437d878115ba700a048b","7e1ab27df68a4615b4c11b66186fb839","3e01ef3deb8a41a88fa46094067ac6cc","a01a6fef6d2b4272a962d79ee483f61e","89eb5bb1577a49c08a4a10f8f9439e00","b16b8b2206f142c88c016a6d52da1822","d418df60ced84a43843aaa1ac450a6d2","24006f00bd944dd1ae22b2eb836dc190","018c50296f154665a2d58ec9d5c21045","a4dbb9cc9c3042268704653eb1eee0bc","c272bed92616443ba27ef521aee6228f","6e128f553472486faab8ec77c15aade6","2978854c12ca4378b3a6655051f4b38e","e94a5335bb8642a7af4fc25db6f2aa04","6b020b0dba054042a990aa453b1c87ad","697de302ab7e47e59e250b971b6dfbfd","81878c1346b84a06a5bee2314a118dff","70047a3c385d4c1db145bd7246424e17","e250ed62fa21442180ac04024072403b","983ea317ecd6458593e58793cc548d98","869683a2ca9f4ca39d1d48fc7c2f9adf","d5abd62683ce4c43a945202668587dc8","835dd391a13a4608a9b281499f196948","32f34afe66f448448cb61f1e02587350","058a543eec3a43afb5e59dbbab792120","68496234f5804e0687e52562d0bff392","8ef8bb4794fd487f8688f94b80be1b15","018e1ff78a524933994de3683dc6dfbc","44b912a74f0b4e478d58da45529cd483","7268c01eef21467897c1818354c937ee","7117467a8ea54e0e8805c210e0b38685","054af28dfe584497b589393f48a1811a"]},"id":"7jOTjn3y3AlO","executionInfo":{"status":"ok","timestamp":1740533159897,"user_tz":-540,"elapsed":9756,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"8167375e-0cbc-4d38-e21c-277741aad803"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e47252d733994df58cd8b40232610faa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d99ac6eabc044e4a0de917ded2f76f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db4107ac08d14d01883072f585b886b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c272bed92616443ba27ef521aee6228f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5abd62683ce4c43a945202668587dc8"}},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","# 전체 데이터 로드\n","#df_full = pd.read_csv(\"data.csv\")\n","print(f\"전체 데이터 로드 메모리 사용량: {df_resampled.memory_usage(deep=True).sum() / 1e6:.2f} MB\")\n","\n","# 필요한 컬럼만 로드\n","df_partial = pd.read_csv(\"review_balanced_resampled.csv\", usecols=[\"cleaned_review\"])\n","print(f\"필요한 컬럼만 로드 메모리 사용량: {df_partial.memory_usage(deep=True).sum() / 1e6:.2f} MB\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lG58VoHNFz7H","executionInfo":{"status":"ok","timestamp":1740537092103,"user_tz":-540,"elapsed":2255,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"5beb1164-45b9-4847-85b9-6b4300f32cc0"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["전체 데이터 로드 메모리 사용량: 285.44 MB\n","필요한 컬럼만 로드 메모리 사용량: 53.44 MB\n"]}]},{"cell_type":"code","source":["df_resampled.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":474},"id":"PleP4qlz3Jex","executionInfo":{"status":"ok","timestamp":1740533185095,"user_tz":-540,"elapsed":45,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"a1375725-852d-4bd9-d3e5-dd828d74f9c2"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   review_id  product_id  rating  \\\n","0   65431338     2070763     5.0   \n","1   11913341     1092992     5.0   \n","2   20956603     1494180     5.0   \n","3   59968738     1798273     5.0   \n","4   53871258     1635193     5.0   \n","\n","                                        review_text review_date review_size  \\\n","0                 가죽이 부들부들해서 착화감이 좋아요\\n\\n색깔도 맘에 듭니다  2024-10-10  42(260) 구매   \n","1                 여름에 거의 매일 신고 다녔어요 오래 신어도 편하고 무난해요  2020-09-27      240 구매   \n","2  신발 자체가 너무 이쁘고 키높이도 맘에 들어요! :) 자주 신고 다닐 거 같습니다 ㅎㅎ  2021-10-20      260 구매   \n","3            배송이 빠르고 포장 꼼곰합니다.\\n발볼 넓은 버전도 나왔으면 좋겠네요  2024-05-27      270 구매   \n","4                  내성발톱 있는데 발볼이 좁지 않아서 편하고 무난해서 좋아요  2023-12-30      270 구매   \n","\n","   review_length                             cleaned_review  \\\n","0              5             가죽이 부들부들해서 착화감이 좋아요 색깔도 맘에 듭니다   \n","1              8          여름에 거의 매일 신고 다녔어요 오래 신어도 편하고 무난해요   \n","2              8  신발 자체가 너무 이쁘고 키높이도 맘에 들어요 자주 신고 다닐 거 같습니다   \n","3              9       배송이 빠르고 포장 꼼곰합니다 발볼 넓은 버전도 나왔으면 좋겠네요   \n","4              7           내성발톱 있는데 발볼이 좁지 않아서 편하고 무난해서 좋아요   \n","\n","                                    tokenized_review  \\\n","0                ['가죽', '부들부들해서', '좋아요', '색깔', '듭니']   \n","1  ['여름', '거의', '매일', '신고', '다녔어요', '오래', '신어', '...   \n","2  ['신발', '자체', '이쁘고', '높이', '들어요', '자주', '신고', '...   \n","3  ['배송', '빠르고', '포장', '꼼곰합니', '발볼', '넓은', '버전', ...   \n","4  ['내성발톱', '있는데', '발볼', '좁지', '않아서', '편하고', '무난'...   \n","\n","                   categories  가성비  내구성 및 품질  디자인  배송 및 포장 및 응대  사이즈  착용감  \n","0  ['착용감', '내구성 및 품질', '디자인']    0         1    1             0    0    1  \n","1         ['착용감', '내구성 및 품질']    0         1    0             0    0    1  \n","2                     ['디자인']    0         0    1             0    0    0  \n","3     ['사이즈', '배송 및 포장 및 응대']    0         0    0             1    1    0  \n","4              ['착용감', '사이즈']    0         0    0             0    1    1  "],"text/html":["\n","  <div id=\"df-a61f8324-ac4f-4fdb-931c-2c37a56e669a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review_id</th>\n","      <th>product_id</th>\n","      <th>rating</th>\n","      <th>review_text</th>\n","      <th>review_date</th>\n","      <th>review_size</th>\n","      <th>review_length</th>\n","      <th>cleaned_review</th>\n","      <th>tokenized_review</th>\n","      <th>categories</th>\n","      <th>가성비</th>\n","      <th>내구성 및 품질</th>\n","      <th>디자인</th>\n","      <th>배송 및 포장 및 응대</th>\n","      <th>사이즈</th>\n","      <th>착용감</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>65431338</td>\n","      <td>2070763</td>\n","      <td>5.0</td>\n","      <td>가죽이 부들부들해서 착화감이 좋아요\\n\\n색깔도 맘에 듭니다</td>\n","      <td>2024-10-10</td>\n","      <td>42(260) 구매</td>\n","      <td>5</td>\n","      <td>가죽이 부들부들해서 착화감이 좋아요 색깔도 맘에 듭니다</td>\n","      <td>['가죽', '부들부들해서', '좋아요', '색깔', '듭니']</td>\n","      <td>['착용감', '내구성 및 품질', '디자인']</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11913341</td>\n","      <td>1092992</td>\n","      <td>5.0</td>\n","      <td>여름에 거의 매일 신고 다녔어요 오래 신어도 편하고 무난해요</td>\n","      <td>2020-09-27</td>\n","      <td>240 구매</td>\n","      <td>8</td>\n","      <td>여름에 거의 매일 신고 다녔어요 오래 신어도 편하고 무난해요</td>\n","      <td>['여름', '거의', '매일', '신고', '다녔어요', '오래', '신어', '...</td>\n","      <td>['착용감', '내구성 및 품질']</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20956603</td>\n","      <td>1494180</td>\n","      <td>5.0</td>\n","      <td>신발 자체가 너무 이쁘고 키높이도 맘에 들어요! :) 자주 신고 다닐 거 같습니다 ㅎㅎ</td>\n","      <td>2021-10-20</td>\n","      <td>260 구매</td>\n","      <td>8</td>\n","      <td>신발 자체가 너무 이쁘고 키높이도 맘에 들어요 자주 신고 다닐 거 같습니다</td>\n","      <td>['신발', '자체', '이쁘고', '높이', '들어요', '자주', '신고', '...</td>\n","      <td>['디자인']</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>59968738</td>\n","      <td>1798273</td>\n","      <td>5.0</td>\n","      <td>배송이 빠르고 포장 꼼곰합니다.\\n발볼 넓은 버전도 나왔으면 좋겠네요</td>\n","      <td>2024-05-27</td>\n","      <td>270 구매</td>\n","      <td>9</td>\n","      <td>배송이 빠르고 포장 꼼곰합니다 발볼 넓은 버전도 나왔으면 좋겠네요</td>\n","      <td>['배송', '빠르고', '포장', '꼼곰합니', '발볼', '넓은', '버전', ...</td>\n","      <td>['사이즈', '배송 및 포장 및 응대']</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>53871258</td>\n","      <td>1635193</td>\n","      <td>5.0</td>\n","      <td>내성발톱 있는데 발볼이 좁지 않아서 편하고 무난해서 좋아요</td>\n","      <td>2023-12-30</td>\n","      <td>270 구매</td>\n","      <td>7</td>\n","      <td>내성발톱 있는데 발볼이 좁지 않아서 편하고 무난해서 좋아요</td>\n","      <td>['내성발톱', '있는데', '발볼', '좁지', '않아서', '편하고', '무난'...</td>\n","      <td>['착용감', '사이즈']</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a61f8324-ac4f-4fdb-931c-2c37a56e669a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a61f8324-ac4f-4fdb-931c-2c37a56e669a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a61f8324-ac4f-4fdb-931c-2c37a56e669a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5e731a89-0d2a-4f1e-bb3b-760b3a22a442\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e731a89-0d2a-4f1e-bb3b-760b3a22a442')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5e731a89-0d2a-4f1e-bb3b-760b3a22a442 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_resampled"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# 토큰화 함수\n","def tokenize_function(texts):\n","    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")"],"metadata":{"id":"6Vluzhux3GNl","executionInfo":{"status":"ok","timestamp":1740533165470,"user_tz":-540,"elapsed":2,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#1분 소요\n","tokenized_data = tokenize_function(df_resampled[\"cleaned_review\"].tolist())\n","tokenized_data[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"mk7x-IJH3Pes","executionInfo":{"status":"ok","timestamp":1740533317938,"user_tz":-540,"elapsed":107746,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"9e961389-0ad3-4a82-e625-4c4dd1b4573c"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[    2,  9363,  2052, 23701,  6396,  1633,  2267,  2434,  2052,  5723,\n","           2182,  7177,  2119,  1043,  2170, 11815,     3,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0],\n","         [    2,  4565,  2170,  4167,  4709,  4806,  8649, 10283,  4517,  1327,\n","           6186,  6978,  2088, 13823,  2097,  2182,     3,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0],\n","         [    2,  7420,  4029,  2116,  3760, 13854,  2088,  1754, 11425,  2119,\n","           1043,  2170,  3685,  2182,  4695,  4806, 10046,   568,   555,  2219,\n","           3606,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0],\n","         [    2,  9488,  2052,  5185,  2088,  6211,   679,  2787, 11800,  1123,\n","           2345,   748,  2073,  9916,  2119,  4225,  6076,  1560,  2918,  2203,\n","           2182,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0],\n","         [    2, 16025,  2311,  2734,  1513, 13964,  1123,  2345,  2052,  1557,\n","           2118,  1380,  2227,  2112,  6978,  2088, 13823,  6396,  5723,  2182,\n","              3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0]]),\n"," 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0]]),\n"," 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0]])}"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#batch_size=5000으로 나눠서 처리하여 속도 개선\n","from transformers import BatchEncoding\n","\n","def tokenize_function(texts, batch_size=5000):\n","    encodings = []\n","    for i in range(0, len(texts), batch_size):\n","        batch = texts[i:i+batch_size]\n","        encodings.append(tokenizer(batch, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\"))\n","    return BatchEncoding({k: torch.cat([e[k] for e in encodings]) for k in encodings[0]})\n"],"metadata":{"id":"DgoJyaX23w1j","executionInfo":{"status":"ok","timestamp":1740533345521,"user_tz":-540,"elapsed":4,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#1분54초\n","tokenized_data = tokenize_function(df_resampled[\"cleaned_review\"].tolist())\n","tokenized_data[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"JUotZUuR34AU","executionInfo":{"status":"ok","timestamp":1740533484519,"user_tz":-540,"elapsed":114843,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"8b80e2b2-6533-4338-abc3-5a75d1401856"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[    2,  9363,  2052, 23701,  6396,  1633,  2267,  2434,  2052,  5723,\n","           2182,  7177,  2119,  1043,  2170, 11815,     3,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0],\n","         [    2,  4565,  2170,  4167,  4709,  4806,  8649, 10283,  4517,  1327,\n","           6186,  6978,  2088, 13823,  2097,  2182,     3,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0],\n","         [    2,  7420,  4029,  2116,  3760, 13854,  2088,  1754, 11425,  2119,\n","           1043,  2170,  3685,  2182,  4695,  4806, 10046,   568,   555,  2219,\n","           3606,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0],\n","         [    2,  9488,  2052,  5185,  2088,  6211,   679,  2787, 11800,  1123,\n","           2345,   748,  2073,  9916,  2119,  4225,  6076,  1560,  2918,  2203,\n","           2182,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0],\n","         [    2, 16025,  2311,  2734,  1513, 13964,  1123,  2345,  2052,  1557,\n","           2118,  1380,  2227,  2112,  6978,  2088, 13823,  6396,  5723,  2182,\n","              3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0]]),\n"," 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0]]),\n"," 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0]])}"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["labels = torch.tensor(df_resampled[[\"가성비\", \"내구성 및 품질\", \"디자인\", \"배송 및 포장 및 응대\", \"사이즈\", \"착용감\"]].values, dtype=torch.float32)\n","labels[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LIzyZx5M4cj6","executionInfo":{"status":"ok","timestamp":1740533531286,"user_tz":-540,"elapsed":71,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"48f0705a-ae86-431f-b005-b0c0aed3a888"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 1., 1., 0., 0., 1.],\n","        [0., 1., 0., 0., 0., 1.],\n","        [0., 0., 1., 0., 0., 0.],\n","        [0., 0., 0., 1., 1., 0.],\n","        [0., 0., 0., 0., 1., 1.]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":[],"metadata":{"id":"r5b7jHIxmUxJ"}},{"cell_type":"code","source":["# 클래스 가중치 계산\n","# class_weights = torch.tensor([\n","#     compute_class_weight(\"balanced\", classes=np.array([0, 1]), y=df_resampled[label].values)[1]\n","#     for label in [\"가성비\", \"내구성 및 품질\", \"디자인\", \"배송 및 포장 및 응대\", \"사이즈\", \"착용감\"]\n","# ], dtype=torch.float32).to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTVOlm584mgm","executionInfo":{"status":"ok","timestamp":1740552658954,"user_tz":-540,"elapsed":12,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"870d6b53-3ca4-4bd3-e19a-ba1e7235983e"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-88-b486b8e48d5b>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  class_weights = torch.sqrt(torch.tensor(class_weights, dtype=torch.float32).cuda())\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([1.2515, 1.0926, 1.0247, 1.1180, 1.0851, 0.9685], device='cuda:0')"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["# 클래스 가중치 정규화 (최소 1.0 이상 유지)\n","min_weight = 1.0\n","max_weight = 2.0  # 최대 가중치를 2.0으로 제한\n","\n","normalized_weights = (class_weights - class_weights.min()) / (class_weights.max() - class_weights.min())\n","normalized_weights = normalized_weights * (max_weight - min_weight) + min_weight\n","\n","print(\"정규화된 클래스 가중치:\", normalized_weights)\n","#정규화된 클래스 가중치: tensor([2.0000, 1.3464, 1.1417, 1.4336, 1.3220, 1.0000], device='cuda:0')\n","\n","class_weights = torch.sqrt(torch.tensor(normalized_weights, dtype=torch.float32).cuda())\n","class_weights"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UW2a6Y_QiL_8","executionInfo":{"status":"ok","timestamp":1740552753480,"user_tz":-540,"elapsed":30,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"2f43f3b5-0198-4f30-f0ec-c1ce759300b0"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["정규화된 클래스 가중치: tensor([2.0000, 1.4384, 1.1988, 1.5281, 1.4121, 1.0000], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-89-eb1c3e336301>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  class_weights = torch.sqrt(torch.tensor(normalized_weights, dtype=torch.float32).cuda())\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([1.4142, 1.1993, 1.0949, 1.2362, 1.1883, 1.0000], device='cuda:0')"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["# 데이터셋 클래스\n","class ReviewDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx] for key, val in self.encodings.items()}\n","        item[\"labels\"] = self.labels[idx]\n","        return item\n"],"metadata":{"id":"1Oy6ggUZ4sMP","executionInfo":{"status":"ok","timestamp":1740552766909,"user_tz":-540,"elapsed":2,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["dataset = ReviewDataset(tokenized_data, labels)\n","dataset.__len__()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xy8Y7Tc94tYS","executionInfo":{"status":"ok","timestamp":1740552773750,"user_tz":-540,"elapsed":5,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"3ca32fbb-a8ca-4b31-e785-18dc9d1254ab"},"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["287189"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["train_size = int(0.8 * len(dataset))\n","val_size = int(0.1 * len(dataset))\n","test_size = len(dataset) - train_size - val_size\n","train_size, val_size, test_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wbkONQG05F-Q","executionInfo":{"status":"ok","timestamp":1740552774985,"user_tz":-540,"elapsed":18,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"470d9294-a094-48be-b23a-2d569a58d1c8"},"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(229751, 28718, 28720)"]},"metadata":{},"execution_count":92}]},{"cell_type":"code","source":["train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"],"metadata":{"id":"yNElHY__5PBS","executionInfo":{"status":"ok","timestamp":1740552778517,"user_tz":-540,"elapsed":19,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["# DataLoader 설정 (최적화)\n","gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # GB 단위 변환\n","gpu_memory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzWpiJyB5hej","executionInfo":{"status":"ok","timestamp":1740552780179,"user_tz":-540,"elapsed":5,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"b2a9a980-5fe2-4989-9739-fde4f5597771"},"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15.828320256"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["#batch_size = 32 if gpu_memory > 15 else 16 if gpu_memory > 10 else 8\n","#batch_size = 64\n","batch_size = min(128, batch_size * 2)\n","batch_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZkacCx-5kx1","executionInfo":{"status":"ok","timestamp":1740552782460,"user_tz":-540,"elapsed":45,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"d6282137-ce71-4844-9a6c-facc8358a992"},"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["128"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["gradient_accumulation_steps = 1 if batch_size >= 16 else 2\n","gradient_accumulation_steps"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83kCqaf15pDu","executionInfo":{"status":"ok","timestamp":1740552785727,"user_tz":-540,"elapsed":5,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"934a1782-9446-466d-d10c-a3f52e87c9ff"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["num_workers = min(4, os.cpu_count())\n","num_workers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wVCGkNWH5sWb","executionInfo":{"status":"ok","timestamp":1740552787476,"user_tz":-540,"elapsed":5,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"42fc65c5-a5bc-4ce7-a3c9-daefc5acb683"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["#데이터 로더 (DataLoader) 설정\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True)"],"metadata":{"id":"Hjn5uEFK6RqS","executionInfo":{"status":"ok","timestamp":1740552790160,"user_tz":-540,"elapsed":17,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}}},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","BertForSequenceClassification(\n","  (bert): BertModel(  # 사전 학습된 BERT 모델 (Feature Extractor)\n","    (embeddings): BertEmbeddings(...)  # 입력 단어 임베딩\n","    (encoder): BertEncoder(...)  # Transformer 인코더 (12개 레이어)\n","    (pooler): BertPooler(...)  # [CLS] 토큰의 최종 벡터 변환\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)  # 드롭아웃 적용 (과적합 방지)\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)  # 최종 분류 레이어\n",")\n","\n","```\n","\n"],"metadata":{"id":"4sEKxGK17Fni"}},{"cell_type":"code","source":["# BERT 모델 로드 (Dropout 최적화)\n","model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=6, ignore_mismatched_sizes=True)\n","model.config.hidden_dropout_prob = 0.5 #0.4 #0.3\n","model.config.attention_probs_dropout_prob = 0.5 #0.4 #0.3\n","for name, param in model.named_parameters():\n","    if \"LayerNorm\" in name:\n","        param.requires_grad = False\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"z3T9OSWR6qxx","executionInfo":{"status":"ok","timestamp":1740552795524,"user_tz":-540,"elapsed":1350,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"9032476a-3146-441f-c1b3-296b84c747c5"},"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["# 손실 함수 (가중치 적용)\n","loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n","loss_fn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AEWatWgh7OjF","executionInfo":{"status":"ok","timestamp":1740552808111,"user_tz":-540,"elapsed":4,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"8555bca6-b469-4338-a936-a5a51986c279"},"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BCEWithLogitsLoss()"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","source":["# 옵티마이저 & 학습률 스케줄러\n","#optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=1e-2)\n","optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=5e-2)\n","#lr_scheduler = get_scheduler(\"cosine\", optimizer=optimizer, num_warmup_steps=500, num_training_steps=len(train_loader) * 5)\n","lr_scheduler = get_scheduler(\"cosine\", optimizer=optimizer, num_warmup_steps=1000, num_training_steps=len(train_loader) * 5)\n","\n","# Mixed Precision (AMP) 사용\n","scaler = torch.cuda.amp.GradScaler()\n","batch_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"beAFE9da7SWt","executionInfo":{"status":"ok","timestamp":1740552809683,"user_tz":-540,"elapsed":4,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"7ccf05e7-9e6f-4b5a-aa50-a4b12a90aef9"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-101-93914a6eac13>:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler()\n"]},{"output_type":"execute_result","data":{"text/plain":["128"]},"metadata":{},"execution_count":101}]},{"cell_type":"code","source":["# 빠른 Validation 평가 함수\n","def quick_evaluate(model, val_loader, num_batches=5):\n","    model.eval() #평가 모드로 전환하여 Dropout 비활성화.\n","    total_loss = 0\n","    all_preds, all_labels = [], []\n","\n","    with torch.no_grad():\n","        for i, batch in enumerate(val_loader):\n","            if i >= num_batches:\n","                break\n","\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            loss = loss_fn(outputs.logits, labels)\n","            total_loss += loss.item()\n","\n","            preds = torch.sigmoid(outputs.logits).cpu().numpy() > 0.5 #확률을 0.5 기준으로 변환하여 예측 수행.\n","            all_preds.extend(preds)\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    return total_loss / num_batches, accuracy_score(all_labels, all_preds), f1_score(all_labels, all_preds, average=\"macro\")\n"],"metadata":{"id":"S3-qw28V7Wro","executionInfo":{"status":"ok","timestamp":1740552815295,"user_tz":-540,"elapsed":3,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["# 학습 함수 (train) - Early Stopping 추가 및 출력 개선\n","def train(model, train_loader, val_loader, epochs=5):\n","    best_val_loss = float(\"inf\")\n","    patience = 2 #Early Stopping을 적용하여 3번 연속으로 검증 손실이 개선되지 않으면 학습 중지.\n","    patience_counter = 0\n","    min_delta = 0.0003\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_loss = 0\n","        optimizer.zero_grad()\n","        loop = tqdm(train_loader, leave=True, desc=f\"Epoch {epoch+1}/{epochs}\")\n","\n","        for step, batch in enumerate(loop):\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","\n","            #with torch.cuda.amp.autocast():\n","            #테스트\n","            with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n","                outputs = model(input_ids, attention_mask=attention_mask)\n","                loss = loss_fn(outputs.logits, labels) / gradient_accumulation_steps #작은 배치 크기에서도 충분한 학습 효과를 주기 위해 Gradient Accumulation 적용\n","\n","            scaler.scale(loss).backward() #AMP(자동 혼합 정밀도) 적용.\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) #기울기 폭발(Gradient Explosion) 방지를 위해 최대값 제한\n","\n","            if (step + 1) % gradient_accumulation_steps == 0:\n","                scaler.unscale_(optimizer)\n","                scaler.step(optimizer)\n","                scaler.update()\n","                lr_scheduler.step()\n","                optimizer.zero_grad()\n","\n","            total_loss += loss.item()\n","            loop.set_postfix(loss=total_loss / (step + 1))  # 실시간 loss 출력\n","\n","        val_loss, val_accuracy, val_f1 = quick_evaluate(model, val_loader)\n","        print(f\"Epoch {epoch+1} | Train Loss: {total_loss / len(train_loader):.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.4f} | Val F1: {val_f1:.4f}\")\n"],"metadata":{"id":"s9exqv1A7igO","executionInfo":{"status":"ok","timestamp":1740552818232,"user_tz":-540,"elapsed":11,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}}},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","Epoch 1/5: 100%|██████████| 3590/3590 [19:29<00:00,  3.07it/s, loss=0.261]\n","Epoch 1 | Train Loss: 0.2608 | Val Loss: 0.0775 | Val Acc: 0.9000 | Val F1: 0.9788\n","Epoch 2/5: 100%|██████████| 3590/3590 [19:28<00:00,  3.07it/s, loss=0.0669]\n","Epoch 2 | Train Loss: 0.0669 | Val Loss: 0.0499 | Val Acc: 0.9344 | Val F1: 0.9855\n","Epoch 3/5: 100%|██████████| 3590/3590 [19:27<00:00,  3.08it/s, loss=0.0461]\n","Epoch 3 | Train Loss: 0.0461 | Val Loss: 0.0391 | Val Acc: 0.9531 | Val F1: 0.9892\n","Epoch 4/5: 100%|██████████| 3590/3590 [19:28<00:00,  3.07it/s, loss=0.036]\n","Epoch 4 | Train Loss: 0.0360 | Val Loss: 0.0335 | Val Acc: 0.9531 | Val F1: 0.9900\n","Epoch 5/5: 100%|██████████| 3590/3590 [19:28<00:00,  3.07it/s, loss=0.0338]\n","Epoch 5 | Train Loss: 0.0338 | Val Loss: 0.0337 | Val Acc: 0.9531 | Val F1: 0.9900\n","```\n","\n"],"metadata":{"id":"WguKJGiKlzB9"}},{"cell_type":"markdown","source":["\n","\n","```\n","Epoch 1/5: 100%|██████████| 3590/3590 [19:30<00:00,  3.07it/s, loss=0.253]\n","Epoch 1 | Train Loss: 0.2533 | Val Loss: 0.0735 | Val Acc: 0.8875 | Val F1: 0.9757\n","Epoch 2/5: 100%|██████████| 3590/3590 [19:30<00:00,  3.07it/s, loss=0.0638]\n","Epoch 2 | Train Loss: 0.0638 | Val Loss: 0.0441 | Val Acc: 0.9406 | Val F1: 0.9863\n","Epoch 3/5: 100%|██████████| 3590/3590 [19:27<00:00,  3.07it/s, loss=0.0448]\n","Epoch 3 | Train Loss: 0.0448 | Val Loss: 0.0369 | Val Acc: 0.9500 | Val F1: 0.9887\n","Epoch 4/5: 100%|██████████| 3590/3590 [19:27<00:00,  3.07it/s, loss=0.0389]\n","Epoch 4 | Train Loss: 0.0389 | Val Loss: 0.0352 | Val Acc: 0.9469 | Val F1: 0.9874\n","Epoch 5/5: 100%|██████████| 3590/3590 [19:27<00:00,  3.08it/s, loss=0.0378]\n","Epoch 5 | Train Loss: 0.0378 | Val Loss: 0.0342 | Val Acc: 0.9469 | Val F1: 0.9874\n","```\n","\n"],"metadata":{"id":"-MuLCALE8Ote"}},{"cell_type":"code","source":["# 학습 시작\n","# 13분 25초 / 25분 * 5 = 125분\n","# 1시간 37분 32초\n","train(model, train_loader, val_loader, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HrdLcsz28X5f","outputId":"570a492a-3a11-442f-a625-e0127bd0f2f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/5:  64%|██████▎   | 1142/1795 [11:11<06:23,  1.70it/s, loss=0.459]"]}]},{"cell_type":"markdown","source":["테스트 데이터에서 성능이 95% 이상 유지되면 실사용 가능!   \n","테스트에서 F1-score가 급락하면, 모델이 과적합일 가능성이 있음."],"metadata":{"id":"OuOoRzTbrPmS"}},{"cell_type":"code","source":["test_loss, test_acc, test_f1 = quick_evaluate(model, test_loader)\n","print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f} | Test F1: {test_f1:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DLtWjTl4_iZ4","executionInfo":{"status":"ok","timestamp":1740551300331,"user_tz":-540,"elapsed":2250,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"c801cf94-43f3-4cda-af08-0dc53cecbe4f"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.0344 | Test Acc: 0.9563 | Test F1: 0.9900\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"RUcj9pmnri5D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 저장 (전체 모델 저장 추가)\n","torch.save(model, \"model.pth\")"],"metadata":{"id":"l2KiTxeg_hPd","executionInfo":{"status":"ok","timestamp":1740551784354,"user_tz":-540,"elapsed":6411,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","# 저장된 모델 로드\n","model = torch.load(\"model.pth\")\n","model.eval()  # 평가 모드로 변경\n"],"metadata":{"id":"xvtnMsKx8c3O"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":82,"metadata":{"id":"dviSn4WGgMlq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740551480818,"user_tz":-540,"elapsed":285,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"07426a77-bcd3-48b3-ac89-4ea6f2dec859"},"outputs":[{"output_type":"stream","name":"stdout","text":["예측 확률: tensor([[0.9991, 0.0062, 0.9983, 0.0038, 0.0028, 0.0039]], device='cuda:0')\n","예측 결과 (0=해당 없음, 1=해당): [[1 0 1 0 0 0]]\n"]}],"source":["from transformers import BertTokenizer\n","import torch\n","\n","# BERT 토크나이저 로드\n","tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")\n","\n","# 새로운 리뷰 예제\n","#text = \"이 제품은 가성비가 뛰어나고 디자인이 정말 멋져요!\"\n","text = \"\"\n","inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n","\n","# GPU 사용 가능하면 모델도 GPU로 이동\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","inputs = {key: val.to(device) for key, val in inputs.items()}\n","\n","# 모델 예측 실행\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","\n","# 로짓을 확률로 변환\n","probs = torch.sigmoid(outputs.logits)\n","predictions = (probs > 0.5).int()  # 0.5 이상이면 해당 클래스로 예측\n","\n","print(\"예측 확률:\", probs)\n","print(\"예측 결과 (0=해당 없음, 1=해당):\", predictions.cpu().numpy())\n","\n","\n"]},{"cell_type":"markdown","source":["가성비, 내구성, 디자인, 배송, 사이즈, 착용감"],"metadata":{"id":"TS6nyZx19EJo"}},{"cell_type":"code","source":["class_labels = [\"가성비\", \"내구성\", \"디자인\", \"배송\", \"사이즈\", \"착용감\"]\n"],"metadata":{"id":"nYyjHm0m-l5Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertTokenizer\n","import torch\n","\n","# BERT 토크나이저 로드\n","tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")\n","\n","# 모델을 GPU로 이동\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()  # 평가 모드\n","\n","# 6개 클래스 레이블 정의\n","class_labels = [\"가성비\", \"내구성\", \"디자인\", \"배송\", \"사이즈\", \"착용감\"]\n","\n","# 10개 샘플 리뷰\n","test_samples = [\n","    \"가격 대비 품질이 뛰어나고 디자인도 세련됐어요. 정말 만족합니다.\",\n","    \"신발이 튼튼하고 내구성이 좋아서 오래 신을 수 있을 것 같아요.\",\n","    \"배송이 예상보다 빨랐고, 포장도 꼼꼼하게 잘 되어 있었어요.\",\n","    \"사이즈가 딱 맞고 착화감이 편해서 장시간 신어도 문제 없어요.\",\n","    \"디자인이 너무 예쁘고 색감도 고급스러워요. 선물하기에도 좋아요.\",\n","    \"가격이 너무 비싼데 품질은 기대 이하여서 아쉬웠어요.\",\n","    \"조금만 신었는데 벌써 해지기 시작했어요. 내구성이 너무 약하네요.\",\n","    \"배송이 너무 늦고, 상자도 찌그러져서 왔어요. 기분이 별로네요.\",\n","    \"사이즈가 설명과 다르게 작게 나와서 불편합니다. 교환해야 할 듯.\",\n","    \"사진이랑 색상이 너무 다르게 나와서 실망했어요. 디자인이 별로네요.\"\n","]\n","\n","# 예측 수행 함수\n","def predict_review(texts):\n","    inputs = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n","    inputs = {key: val.to(device) for key, val in inputs.items()}\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    probs = torch.sigmoid(outputs.logits)  # 확률 변환\n","    predictions = (probs > 0.5).int()  # 0.5 이상이면 해당 클래스로 예측\n","\n","    return probs.cpu().numpy(), predictions.cpu().numpy()\n","\n","# 10개 샘플 예측\n","probs, preds = predict_review(test_samples)\n","\n","# 결과 출력\n","for i, (review, prob, pred) in enumerate(zip(test_samples, probs, preds)):\n","    predicted_labels = [class_labels[j] for j in range(len(class_labels)) if pred[j] == 1]  # 1인 레이블만 선택\n","\n","    print(f\"📝 리뷰 {i+1}: {review}\")\n","    print(f\"🔹 예측된 라벨: {predicted_labels if predicted_labels else ['해당 없음']}\")\n","    print(\"-\" * 80)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yyvf1rzsWh4","executionInfo":{"status":"ok","timestamp":1740552093459,"user_tz":-540,"elapsed":390,"user":{"displayName":"하늘삧깔영리쌤","userId":"05963616512057987832"}},"outputId":"fdbef0fa-2635-49c5-caa1-46279d9ed37f"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["📝 리뷰 1: 가격 대비 품질이 뛰어나고 디자인도 세련됐어요. 정말 만족합니다.\n","🔹 예측된 라벨: ['가성비', '내구성', '디자인']\n","--------------------------------------------------------------------------------\n","📝 리뷰 2: 신발이 튼튼하고 내구성이 좋아서 오래 신을 수 있을 것 같아요.\n","🔹 예측된 라벨: ['내구성']\n","--------------------------------------------------------------------------------\n","📝 리뷰 3: 배송이 예상보다 빨랐고, 포장도 꼼꼼하게 잘 되어 있었어요.\n","🔹 예측된 라벨: ['배송']\n","--------------------------------------------------------------------------------\n","📝 리뷰 4: 사이즈가 딱 맞고 착화감이 편해서 장시간 신어도 문제 없어요.\n","🔹 예측된 라벨: ['사이즈', '착용감']\n","--------------------------------------------------------------------------------\n","📝 리뷰 5: 디자인이 너무 예쁘고 색감도 고급스러워요. 선물하기에도 좋아요.\n","🔹 예측된 라벨: ['디자인']\n","--------------------------------------------------------------------------------\n","📝 리뷰 6: 가격이 너무 비싼데 품질은 기대 이하여서 아쉬웠어요.\n","🔹 예측된 라벨: ['가성비', '내구성']\n","--------------------------------------------------------------------------------\n","📝 리뷰 7: 조금만 신었는데 벌써 해지기 시작했어요. 내구성이 너무 약하네요.\n","🔹 예측된 라벨: ['내구성']\n","--------------------------------------------------------------------------------\n","📝 리뷰 8: 배송이 너무 늦고, 상자도 찌그러져서 왔어요. 기분이 별로네요.\n","🔹 예측된 라벨: ['배송']\n","--------------------------------------------------------------------------------\n","📝 리뷰 9: 사이즈가 설명과 다르게 작게 나와서 불편합니다. 교환해야 할 듯.\n","🔹 예측된 라벨: ['사이즈', '착용감']\n","--------------------------------------------------------------------------------\n","📝 리뷰 10: 사진이랑 색상이 너무 다르게 나와서 실망했어요. 디자인이 별로네요.\n","🔹 예측된 라벨: ['디자인']\n","--------------------------------------------------------------------------------\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OX2KpgecsWYn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 첫번째 결과\n","2025-02-25 20:16:31.314967: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-02-25 20:16:31.316332: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2025-02-25 20:16:31.320181: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2025-02-25 20:16:31.332216: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1740482191.353197   16073 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1740482191.359222   16073 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-02-25 20:16:31.379992: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","Using device: cuda\n","GPU: Tesla T4\n","/home/ubuntu/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/home/ubuntu/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","Epoch 1/5: 100%|██████████| 7180/7180 [25:37<00:00,  4.67it/s, loss=0.162]\n","Epoch 1 | Train Loss: 0.1615 | Val Loss: 0.0531 | Val Acc: 0.9250 | Val F1: 0.9834\n","Epoch 2/5: 100%|██████████| 7180/7180 [25:37<00:00,  4.67it/s, loss=0.0363]\n","Epoch 2 | Train Loss: 0.0363 | Val Loss: 0.0067 | Val Acc: 0.9875 | Val F1: 0.9972\n","Epoch 3/5: 100%|██████████| 7180/7180 [25:30<00:00,  4.69it/s, loss=0.0221]\n","Epoch 3 | Train Loss: 0.0221 | Val Loss: 0.0042 | Val Acc: 0.9875 | Val F1: 0.9972\n","Epoch 4/5: 100%|██████████| 7180/7180 [25:33<00:00,  4.68it/s, loss=0.0196]\n","Epoch 4 | Train Loss: 0.0196 | Val Loss: 0.0084 | Val Acc: 0.9875 | Val F1: 0.9981\n","Epoch 5/5: 100%|██████████| 7180/7180 [25:35<00:00,  4.68it/s, loss=0.0189]\n","Epoch 5 | Train Loss: 0.0189 | Val Loss: 0.0079 | Val Acc: 0.9875 | Val F1: 0.9972\n"],"metadata":{"id":"o_QXlpIHZOqi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RlXG7jiuu7e7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AGGC4u09u7mX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jnEF4AYuu7pR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XwRTiPP3u7r3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 수요일에 돌려볼 코드\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pandas as pd\n","import numpy as np\n","from transformers import BertTokenizer, BertForSequenceClassification, get_scheduler\n","from torch.utils.data import DataLoader, random_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, accuracy_score\n","\n","# GPU 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.backends.cudnn.benchmark = True\n","print(f\"Using device: {device}\")\n","\n","# 데이터 로드\n","df_resampled = pd.read_csv(\"./review_balanced_resampled.csv\")\n","\n","# 배치 크기 조정 (VRAM 최적화)\n","gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n","batch_size = 16  # Tesla T4 (15GB) 기준 최적화\n","\n","# 토크나이저 로드 및 데이터 변환\n","tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")\n","tokenized_data = tokenizer(df_resampled[\"cleaned_review\"].tolist(), padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n","labels = torch.tensor(df_resampled[[\"가성비\", \"내구성 및 품질\", \"디자인\", \"배송 및 포장 및 응대\", \"사이즈\", \"착용감\"]].values, dtype=torch.float32)\n","\n","# 데이터셋 구성\n","dataset = torch.utils.data.TensorDataset(tokenized_data[\"input_ids\"], tokenized_data[\"attention_mask\"], labels)\n","train_size = int(0.8 * len(dataset))\n","val_size = int(0.1 * len(dataset))\n","test_size = len(dataset) - train_size - val_size\n","train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n","\n","# DataLoader 설정\n","num_workers = min(4, os.cpu_count())\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","# BERT 모델 로드 및 설정 최적화 (Dropout 0.4)\n","model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=6)\n","model.config.hidden_dropout_prob = 0.4\n","model.config.attention_probs_dropout_prob = 0.4\n","model.to(device)\n","\n","# 손실 함수 및 옵티마이저\n","class_weights = torch.tensor([\n","    compute_class_weight(\"balanced\", classes=np.array([0, 1]), y=df_resampled[label].values)[1]\n","    for label in [\"가성비\", \"내구성 및 품질\", \"디자인\", \"배송 및 포장 및 응대\", \"사이즈\", \"착용감\"]\n","], dtype=torch.float32).to(device)\n","\n","loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n","optimizer = optim.AdamW(model.parameters(), lr=1.2e-5, weight_decay=5e-3)\n","\n","# 학습률 스케줄러 (10% Warmup)\n","lr_scheduler = get_scheduler(\"cosine\", optimizer=optimizer, num_warmup_steps=int(len(train_loader) * 0.1), num_training_steps=len(train_loader) * 7)\n","\n","# Mixed Precision Training 추가\n","scaler = torch.cuda.amp.GradScaler()\n","\n","# 학습 함수 (Gradient Accumulation Steps 최적화)\n","def train(model, train_loader, val_loader, epochs=7, patience=5, min_delta=0.001):\n","    best_val_loss = float(\"inf\")\n","    patience_counter = 0\n","    gradient_accumulation_steps = 4  # batch_size 16에 맞춰 증가\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_loss = 0\n","        optimizer.zero_grad()\n","        loop = tqdm(train_loader, leave=True, desc=f\"Epoch {epoch+1}/{epochs}\")\n","\n","        for step, batch in enumerate(loop):\n","            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n","\n","            with torch.cuda.amp.autocast():  # Mixed Precision 적용\n","                outputs = model(input_ids, attention_mask=attention_mask)\n","                loss = loss_fn(outputs.logits, labels) / gradient_accumulation_steps\n","\n","            scaler.scale(loss).backward()\n","            if (step + 1) % gradient_accumulation_steps == 0:\n","                scaler.unscale_(optimizer)\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","                scaler.step(optimizer)\n","                scaler.update()\n","                lr_scheduler.step()\n","                optimizer.zero_grad()\n","\n","            total_loss += loss.item()\n","            loop.set_postfix(loss=total_loss / len(train_loader))\n","\n","        val_loss, val_acc, val_f1 = evaluate(model, val_loader)\n","        print(f\"Epoch {epoch+1} | Train Loss: {total_loss / len(train_loader):.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")\n","\n","        if val_loss < best_val_loss - min_delta:\n","            best_val_loss = val_loss\n","            patience_counter = 0\n","            torch.save(model.state_dict(), \"best_model.pth\")\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= patience:\n","                print(\"Early stopping activated!\")\n","                break\n","\n","# Validation 평가 함수\n","def evaluate(model, val_loader, threshold=0.5):\n","    model.eval()\n","    total_loss = 0\n","    all_preds, all_labels = [], []\n","\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            loss = loss_fn(outputs.logits, labels)\n","            total_loss += loss.item()\n","\n","            probs = torch.sigmoid(outputs.logits).cpu().numpy()\n","            preds = (probs > threshold).astype(int)\n","            all_preds.extend(preds)\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    return total_loss / len(val_loader), accuracy_score(all_labels, all_preds), f1_score(all_labels, all_preds, average=\"macro\", zero_division=1)\n","\n","# 학습 시작\n","train(model, train_loader, val_loader, epochs=7)\n","\n","# Test 데이터 최적 평가\n","model.load_state_dict(torch.load(\"best_model.pth\"))\n","for threshold in [0.4, 0.5, 0.6]:\n","    test_loss, test_acc, test_f1 = evaluate(model, test_loader, threshold=threshold)\n","    print(f\"Threshold {threshold} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f} | Test F1: {test_f1:.4f}\")\n"],"metadata":{"id":"94I7qx7pu7uj"},"execution_count":null,"outputs":[]}]}