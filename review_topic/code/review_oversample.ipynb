{"cells":[{"cell_type":"code","execution_count":null,"id":"b48503ae-ede7-4403-9e35-4acddc1cc620","metadata":{"id":"b48503ae-ede7-4403-9e35-4acddc1cc620","outputId":"1ba35a38-ff78-465a-b2d8-7a08020613d5"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-02-26 14:35:57.492217: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-02-26 14:35:57.493511: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2025-02-26 14:35:57.496906: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2025-02-26 14:35:57.508152: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1740548157.527144   25917 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1740548157.532838   25917 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-02-26 14:35:57.552013: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["# 모델 돌린 코드\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pandas as pd\n","import numpy as np\n","from transformers import BertTokenizer, BertForSequenceClassification, get_scheduler\n","from torch.utils.data import DataLoader, random_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, accuracy_score\n","from transformers import logging\n","\n","# 불필요한 경고 메시지 숨기기\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","logging.set_verbosity_error()\n"]},{"cell_type":"code","execution_count":null,"id":"e0c29b39-95ad-48f5-bf15-714941f8ff7a","metadata":{"id":"e0c29b39-95ad-48f5-bf15-714941f8ff7a","outputId":"8b7731b1-ac7a-4ab2-cfdf-22c416cf7547"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n","GPU: Tesla T4\n"]}],"source":["\n","# GPU 설정 및 최적화\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.backends.cudnn.benchmark = True  # 연산 최적화 활성화\n","print(f\"Using device: {device}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"]},{"cell_type":"code","execution_count":null,"id":"b9621a23-e147-430b-baea-d039c5a58ee4","metadata":{"id":"b9621a23-e147-430b-baea-d039c5a58ee4","outputId":"5bd4733d-8dda-457f-c8e7-4834f80f3afa"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}],"source":["# 데이터 로드\n","df_resampled = pd.read_csv(\"./review_balanced_resampled.csv\")\n","\n","# BERT 토크나이저 로드\n","tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")"]},{"cell_type":"code","execution_count":null,"id":"78a76091-2970-4b2c-a9c3-34e075408046","metadata":{"id":"78a76091-2970-4b2c-a9c3-34e075408046","outputId":"bc4c90a6-ef08-4fda-d035-2c7e50625cc1"},"outputs":[{"name":"stdout","output_type":"stream","text":["전체 데이터 로드 메모리 사용량: 285.44 MB\n","필요한 컬럼만 로드 메모리 사용량: 53.44 MB\n"]}],"source":["import pandas as pd\n","import os\n","\n","# 전체 데이터 로드\n","#df_full = pd.read_csv(\"data.csv\")\n","print(f\"전체 데이터 로드 메모리 사용량: {df_resampled.memory_usage(deep=True).sum() / 1e6:.2f} MB\")\n","\n","# 필요한 컬럼만 로드\n","df_partial = pd.read_csv(\"review_balanced_resampled.csv\", usecols=[\"cleaned_review\"])\n","print(f\"필요한 컬럼만 로드 메모리 사용량: {df_partial.memory_usage(deep=True).sum() / 1e6:.2f} MB\")\n"]},{"cell_type":"code","execution_count":null,"id":"01ddb655-539c-4708-8890-e8110b6fcef3","metadata":{"id":"01ddb655-539c-4708-8890-e8110b6fcef3","outputId":"fc08a058-69e2-44d4-bad6-0e4e31cc007e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review_id</th>\n","      <th>product_id</th>\n","      <th>rating</th>\n","      <th>review_text</th>\n","      <th>review_date</th>\n","      <th>review_size</th>\n","      <th>review_length</th>\n","      <th>cleaned_review</th>\n","      <th>tokenized_review</th>\n","      <th>categories</th>\n","      <th>가성비</th>\n","      <th>내구성 및 품질</th>\n","      <th>디자인</th>\n","      <th>배송 및 포장 및 응대</th>\n","      <th>사이즈</th>\n","      <th>착용감</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>65431338</td>\n","      <td>2070763</td>\n","      <td>5.0</td>\n","      <td>가죽이 부들부들해서 착화감이 좋아요\\n\\n색깔도 맘에 듭니다</td>\n","      <td>2024-10-10</td>\n","      <td>42(260) 구매</td>\n","      <td>5</td>\n","      <td>가죽이 부들부들해서 착화감이 좋아요 색깔도 맘에 듭니다</td>\n","      <td>['가죽', '부들부들해서', '좋아요', '색깔', '듭니']</td>\n","      <td>['착용감', '내구성 및 품질', '디자인']</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11913341</td>\n","      <td>1092992</td>\n","      <td>5.0</td>\n","      <td>여름에 거의 매일 신고 다녔어요 오래 신어도 편하고 무난해요</td>\n","      <td>2020-09-27</td>\n","      <td>240 구매</td>\n","      <td>8</td>\n","      <td>여름에 거의 매일 신고 다녔어요 오래 신어도 편하고 무난해요</td>\n","      <td>['여름', '거의', '매일', '신고', '다녔어요', '오래', '신어', '...</td>\n","      <td>['착용감', '내구성 및 품질']</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20956603</td>\n","      <td>1494180</td>\n","      <td>5.0</td>\n","      <td>신발 자체가 너무 이쁘고 키높이도 맘에 들어요! :) 자주 신고 다닐 거 같습니다 ㅎㅎ</td>\n","      <td>2021-10-20</td>\n","      <td>260 구매</td>\n","      <td>8</td>\n","      <td>신발 자체가 너무 이쁘고 키높이도 맘에 들어요 자주 신고 다닐 거 같습니다</td>\n","      <td>['신발', '자체', '이쁘고', '높이', '들어요', '자주', '신고', '...</td>\n","      <td>['디자인']</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>59968738</td>\n","      <td>1798273</td>\n","      <td>5.0</td>\n","      <td>배송이 빠르고 포장 꼼곰합니다.\\n발볼 넓은 버전도 나왔으면 좋겠네요</td>\n","      <td>2024-05-27</td>\n","      <td>270 구매</td>\n","      <td>9</td>\n","      <td>배송이 빠르고 포장 꼼곰합니다 발볼 넓은 버전도 나왔으면 좋겠네요</td>\n","      <td>['배송', '빠르고', '포장', '꼼곰합니', '발볼', '넓은', '버전', ...</td>\n","      <td>['사이즈', '배송 및 포장 및 응대']</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>53871258</td>\n","      <td>1635193</td>\n","      <td>5.0</td>\n","      <td>내성발톱 있는데 발볼이 좁지 않아서 편하고 무난해서 좋아요</td>\n","      <td>2023-12-30</td>\n","      <td>270 구매</td>\n","      <td>7</td>\n","      <td>내성발톱 있는데 발볼이 좁지 않아서 편하고 무난해서 좋아요</td>\n","      <td>['내성발톱', '있는데', '발볼', '좁지', '않아서', '편하고', '무난'...</td>\n","      <td>['착용감', '사이즈']</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   review_id  product_id  rating  \\\n","0   65431338     2070763     5.0   \n","1   11913341     1092992     5.0   \n","2   20956603     1494180     5.0   \n","3   59968738     1798273     5.0   \n","4   53871258     1635193     5.0   \n","\n","                                        review_text review_date review_size  \\\n","0                 가죽이 부들부들해서 착화감이 좋아요\\n\\n색깔도 맘에 듭니다  2024-10-10  42(260) 구매   \n","1                 여름에 거의 매일 신고 다녔어요 오래 신어도 편하고 무난해요  2020-09-27      240 구매   \n","2  신발 자체가 너무 이쁘고 키높이도 맘에 들어요! :) 자주 신고 다닐 거 같습니다 ㅎㅎ  2021-10-20      260 구매   \n","3            배송이 빠르고 포장 꼼곰합니다.\\n발볼 넓은 버전도 나왔으면 좋겠네요  2024-05-27      270 구매   \n","4                  내성발톱 있는데 발볼이 좁지 않아서 편하고 무난해서 좋아요  2023-12-30      270 구매   \n","\n","   review_length                             cleaned_review  \\\n","0              5             가죽이 부들부들해서 착화감이 좋아요 색깔도 맘에 듭니다   \n","1              8          여름에 거의 매일 신고 다녔어요 오래 신어도 편하고 무난해요   \n","2              8  신발 자체가 너무 이쁘고 키높이도 맘에 들어요 자주 신고 다닐 거 같습니다   \n","3              9       배송이 빠르고 포장 꼼곰합니다 발볼 넓은 버전도 나왔으면 좋겠네요   \n","4              7           내성발톱 있는데 발볼이 좁지 않아서 편하고 무난해서 좋아요   \n","\n","                                    tokenized_review  \\\n","0                ['가죽', '부들부들해서', '좋아요', '색깔', '듭니']   \n","1  ['여름', '거의', '매일', '신고', '다녔어요', '오래', '신어', '...   \n","2  ['신발', '자체', '이쁘고', '높이', '들어요', '자주', '신고', '...   \n","3  ['배송', '빠르고', '포장', '꼼곰합니', '발볼', '넓은', '버전', ...   \n","4  ['내성발톱', '있는데', '발볼', '좁지', '않아서', '편하고', '무난'...   \n","\n","                   categories  가성비  내구성 및 품질  디자인  배송 및 포장 및 응대  사이즈  착용감  \n","0  ['착용감', '내구성 및 품질', '디자인']    0         1    1             0    0    1  \n","1         ['착용감', '내구성 및 품질']    0         1    0             0    0    1  \n","2                     ['디자인']    0         0    1             0    0    0  \n","3     ['사이즈', '배송 및 포장 및 응대']    0         0    0             1    1    0  \n","4              ['착용감', '사이즈']    0         0    0             0    1    1  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_resampled.head(5)"]},{"cell_type":"code","execution_count":null,"id":"07f060a1-462b-41e7-b943-6bd54e148353","metadata":{"id":"07f060a1-462b-41e7-b943-6bd54e148353"},"outputs":[],"source":["#batch_size=5000으로 나눠서 처리하여 속도 개선\n","from transformers import BatchEncoding\n","\n","def tokenize_function(texts, batch_size=5000):\n","    encodings = []\n","    for i in range(0, len(texts), batch_size):\n","        batch = texts[i:i+batch_size]\n","        encodings.append(tokenizer(batch, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\"))\n","    return BatchEncoding({k: torch.cat([e[k] for e in encodings]) for k in encodings[0]})"]},{"cell_type":"code","execution_count":null,"id":"8b7e7181-9898-4d33-907d-70f2e5b19bfe","metadata":{"id":"8b7e7181-9898-4d33-907d-70f2e5b19bfe"},"outputs":[],"source":["#1분54초\n","tokenized_data = tokenize_function(df_resampled[\"cleaned_review\"].tolist())"]},{"cell_type":"code","execution_count":null,"id":"e1ddd967-59d1-48df-a27a-7a10af8290da","metadata":{"id":"e1ddd967-59d1-48df-a27a-7a10af8290da","outputId":"d1b16b10-d08c-4fe3-c338-801c8f361b84"},"outputs":[{"data":{"text/plain":["tensor([[0., 1., 1., 0., 0., 1.],\n","        [0., 1., 0., 0., 0., 1.],\n","        [0., 0., 1., 0., 0., 0.],\n","        [0., 0., 0., 1., 1., 0.],\n","        [0., 0., 0., 0., 1., 1.]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["labels = torch.tensor(df_resampled[[\"가성비\", \"내구성 및 품질\", \"디자인\", \"배송 및 포장 및 응대\", \"사이즈\", \"착용감\"]].values, dtype=torch.float32)\n","labels[:5]"]},{"cell_type":"code","execution_count":null,"id":"40756d8d-0da7-4fae-b4a7-29824b1800a6","metadata":{"id":"40756d8d-0da7-4fae-b4a7-29824b1800a6","outputId":"ea5ca2ac-2906-4c58-b8c6-d4ea82281a0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["정규화된 클래스 가중치: tensor([2.0000, 1.3464, 1.1417, 1.4336, 1.3220, 1.0000], device='cuda:0')\n","제곱근 적용된 클래스 가중치: tensor([1.4142, 1.1604, 1.0685, 1.1973, 1.1498, 1.0000], device='cuda:0')\n"]}],"source":["# 클래스 가중치 계산\n","class_weights = torch.tensor([\n","    compute_class_weight(\"balanced\", classes=np.array([0, 1]), y=df_resampled[label].values)[1]\n","    for label in [\"가성비\", \"내구성 및 품질\", \"디자인\", \"배송 및 포장 및 응대\", \"사이즈\", \"착용감\"]\n","], dtype=torch.float32).to(device)\n","\n","# 클래스 가중치 정규화 (최소 1.0 이상 유지)\n","min_weight = 1.0\n","max_weight = 2.0  # 최대 가중치를 2.0으로 제한\n","\n","normalized_weights = (class_weights - class_weights.min()) / (class_weights.max() - class_weights.min())\n","normalized_weights = normalized_weights * (max_weight - min_weight) + min_weight\n","\n","print(\"정규화된 클래스 가중치:\", normalized_weights)\n","\n","# 가중치에 제곱근 적용\n","sqrt_weights = torch.sqrt(normalized_weights)\n","\n","print(\"제곱근 적용된 클래스 가중치:\", sqrt_weights)\n"]},{"cell_type":"code","execution_count":null,"id":"8be24230-52b6-416f-bd55-678f2b35bad6","metadata":{"id":"8be24230-52b6-416f-bd55-678f2b35bad6"},"outputs":[],"source":["# 데이터셋 클래스\n","class ReviewDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx] for key, val in self.encodings.items()}\n","        item[\"labels\"] = self.labels[idx]\n","        return item"]},{"cell_type":"code","execution_count":null,"id":"df38fedc-7cd0-4d95-ae7f-d2effdd79d39","metadata":{"id":"df38fedc-7cd0-4d95-ae7f-d2effdd79d39","outputId":"5ca0e305-ffcc-4a8f-d93e-8a46016b9452"},"outputs":[{"data":{"text/plain":["287189"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["dataset = ReviewDataset(tokenized_data, labels)\n","dataset.__len__()"]},{"cell_type":"code","execution_count":null,"id":"60130078-17d0-4c81-8fb4-3264bc318b4a","metadata":{"id":"60130078-17d0-4c81-8fb4-3264bc318b4a","outputId":"d1677c04-f688-44ee-a5da-f3acfc029343"},"outputs":[{"data":{"text/plain":["(229751, 28718, 28720)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train_size = int(0.8 * len(dataset))\n","val_size = int(0.1 * len(dataset))\n","test_size = len(dataset) - train_size - val_size\n","train_size, val_size, test_size"]},{"cell_type":"code","execution_count":null,"id":"4bdce3bd-7d97-4699-84d3-080f8970efde","metadata":{"id":"4bdce3bd-7d97-4699-84d3-080f8970efde"},"outputs":[],"source":["train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"]},{"cell_type":"code","execution_count":null,"id":"e16e0dcd-de51-4e48-88a2-f94099bf59b6","metadata":{"id":"e16e0dcd-de51-4e48-88a2-f94099bf59b6","outputId":"f2bf88e6-80dc-442c-e229-e7bbce807136"},"outputs":[{"data":{"text/plain":["15.655829504"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# DataLoader 설정 (최적화)\n","gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # GB 단위 변환\n","gpu_memory"]},{"cell_type":"code","execution_count":null,"id":"8d77b03e-6366-4351-8194-415d6c8d8862","metadata":{"id":"8d77b03e-6366-4351-8194-415d6c8d8862"},"outputs":[],"source":["#batch_size = 32 if gpu_memory > 15 else 16 if gpu_memory > 10 else 8\n","batch_size = 64"]},{"cell_type":"code","execution_count":null,"id":"fb31f308-ba1e-46c4-b5ed-fd6ea1b9c5e5","metadata":{"id":"fb31f308-ba1e-46c4-b5ed-fd6ea1b9c5e5","outputId":"3b6c955e-9c9b-4f3d-e674-489e0781d450"},"outputs":[{"data":{"text/plain":["1"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["gradient_accumulation_steps = 1 if batch_size >= 16 else 2\n","gradient_accumulation_steps"]},{"cell_type":"code","execution_count":null,"id":"91946f44-be0d-4325-bb42-89b5da3408cc","metadata":{"id":"91946f44-be0d-4325-bb42-89b5da3408cc","outputId":"65723de0-6022-44a2-9614-bb595697e8d9"},"outputs":[{"data":{"text/plain":["4"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["num_workers = min(4, os.cpu_count())\n","num_workers"]},{"cell_type":"code","execution_count":null,"id":"c4675ea2-7a21-4040-80dd-fe3347f17065","metadata":{"id":"c4675ea2-7a21-4040-80dd-fe3347f17065"},"outputs":[],"source":["#데이터 로더 (DataLoader) 설정\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True)"]},{"cell_type":"code","execution_count":null,"id":"259b61c8-6a82-4f7b-b408-811e3e41e9b9","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"259b61c8-6a82-4f7b-b408-811e3e41e9b9","outputId":"0aea90c4-5435-4e19-9586-0a6bedfa4fec"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# BERT 모델 로드 (Dropout 최적화)\n","model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=6, ignore_mismatched_sizes=True)\n","model.config.hidden_dropout_prob = 0.5 #0.4 #0.3\n","model.config.attention_probs_dropout_prob = 0.5 #0.4 #0.3\n","for name, param in model.named_parameters():\n","    if \"LayerNorm\" in name:\n","        param.requires_grad = False\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"id":"6282262d-c01b-4960-99cb-2aa9c8483ba8","metadata":{"id":"6282262d-c01b-4960-99cb-2aa9c8483ba8","outputId":"2473acff-dcc6-4503-be27-ad60e762e192"},"outputs":[{"data":{"text/plain":["BCEWithLogitsLoss()"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# 손실 함수 (가중치 적용)\n","loss_fn = nn.BCEWithLogitsLoss(pos_weight=sqrt_weights)\n","loss_fn"]},{"cell_type":"code","execution_count":null,"id":"f08275e6-94ee-4a3e-b12e-b74ccaa2242b","metadata":{"id":"f08275e6-94ee-4a3e-b12e-b74ccaa2242b","outputId":"c4f88a41-4dcd-4b24-b90c-a840cf39f86c"},"outputs":[{"data":{"text/plain":["64"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# 옵티마이저 & 학습률 스케줄러\n","optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=5e-2)\n","lr_scheduler = get_scheduler(\"cosine\", optimizer=optimizer, num_warmup_steps=1000, num_training_steps=len(train_loader) * 5)\n","\n","# Mixed Precision (AMP) 사용\n","scaler = torch.cuda.amp.GradScaler()\n","batch_size"]},{"cell_type":"code","execution_count":null,"id":"3ff744cd-16d5-4dca-bfa0-7ecce6b0aae5","metadata":{"id":"3ff744cd-16d5-4dca-bfa0-7ecce6b0aae5"},"outputs":[],"source":["# 빠른 Validation 평가 함수\n","def quick_evaluate(model, val_loader, num_batches=5):\n","    model.eval() #평가 모드로 전환하여 Dropout 비활성화.\n","    total_loss = 0\n","    all_preds, all_labels = [], []\n","\n","    with torch.no_grad():\n","        for i, batch in enumerate(val_loader):\n","            if i >= num_batches:\n","                break\n","\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            loss = loss_fn(outputs.logits, labels)\n","            total_loss += loss.item()\n","\n","            preds = torch.sigmoid(outputs.logits).cpu().numpy() > 0.5 #확률을 0.5 기준으로 변환하여 예측 수행.\n","            all_preds.extend(preds)\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    return total_loss / num_batches, accuracy_score(all_labels, all_preds), f1_score(all_labels, all_preds, average=\"macro\")\n"]},{"cell_type":"code","execution_count":null,"id":"9ad7da70-3d9c-4109-8eaf-cee9f17a48f5","metadata":{"id":"9ad7da70-3d9c-4109-8eaf-cee9f17a48f5"},"outputs":[],"source":["# 학습 함수 (train) - Early Stopping 추가 및 출력 개선\n","def train(model, train_loader, val_loader, epochs=5):\n","    best_val_loss = float(\"inf\")\n","    patience = 2 #Early Stopping을 적용하여 3번 연속으로 검증 손실이 개선되지 않으면 학습 중지.\n","    patience_counter = 0\n","    min_delta = 0.0003\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_loss = 0\n","        optimizer.zero_grad()\n","        loop = tqdm(train_loader, leave=True, desc=f\"Epoch {epoch+1}/{epochs}\")\n","\n","        for step, batch in enumerate(loop):\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","\n","            #with torch.cuda.amp.autocast():\n","            #테스트\n","            with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n","                outputs = model(input_ids, attention_mask=attention_mask)\n","                loss = loss_fn(outputs.logits, labels) / gradient_accumulation_steps #작은 배치 크기에서도 충분한 학습 효과를 주기 위해 Gradient Accumulation 적용\n","\n","            scaler.scale(loss).backward() #AMP(자동 혼합 정밀도) 적용.\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) #기울기 폭발(Gradient Explosion) 방지를 위해 최대값 제한\n","\n","            if (step + 1) % gradient_accumulation_steps == 0:\n","                scaler.unscale_(optimizer)\n","                scaler.step(optimizer)\n","                scaler.update()\n","                lr_scheduler.step()\n","                optimizer.zero_grad()\n","\n","            total_loss += loss.item()\n","            loop.set_postfix(loss=total_loss / (step + 1))  # 실시간 loss 출력\n","\n","        val_loss, val_accuracy, val_f1 = quick_evaluate(model, val_loader)\n","        print(f\"Epoch {epoch+1} | Train Loss: {total_loss / len(train_loader):.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.4f} | Val F1: {val_f1:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"54544264-785c-4b12-955d-ba3e5d7581b9","metadata":{"id":"54544264-785c-4b12-955d-ba3e5d7581b9","outputId":"0cd82de4-84fe-4854-de74-2babf5210179"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 3590/3590 [41:14<00:00,  1.45it/s, loss=0.231]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 | Train Loss: 0.2309 | Val Loss: 0.0651 | Val Acc: 0.9031 | Val F1: 0.9794\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 3590/3590 [21:09<00:00,  2.83it/s, loss=0.0596]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 | Train Loss: 0.0596 | Val Loss: 0.0381 | Val Acc: 0.9406 | Val F1: 0.9872\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 3590/3590 [21:06<00:00,  2.84it/s, loss=0.0423]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 | Train Loss: 0.0423 | Val Loss: 0.0304 | Val Acc: 0.9563 | Val F1: 0.9902\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 3590/3590 [21:06<00:00,  2.83it/s, loss=0.0367]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 | Train Loss: 0.0367 | Val Loss: 0.0284 | Val Acc: 0.9625 | Val F1: 0.9911\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 3590/3590 [21:06<00:00,  2.84it/s, loss=0.035] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 | Train Loss: 0.0350 | Val Loss: 0.0280 | Val Acc: 0.9625 | Val F1: 0.9911\n"]}],"source":["# 학습 시작\n","# 13분 25초 / 25분 * 5 = 125분\n","# 1시간 37분 32초\n","train(model, train_loader, val_loader, epochs=5)"]},{"cell_type":"code","execution_count":null,"id":"0c645e60-a8c1-4275-85eb-771e5514ca9a","metadata":{"id":"0c645e60-a8c1-4275-85eb-771e5514ca9a","outputId":"bb39bd55-59cd-4861-b7ff-c9ecd0f13f1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Loss: 0.0229 | Test Acc: 0.9594 | Test F1: 0.9920\n"]}],"source":["test_loss, test_acc, test_f1 = quick_evaluate(model, test_loader)\n","print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f} | Test F1: {test_f1:.4f}\")"]},{"cell_type":"code","execution_count":null,"id":"ef7bb34f-6ac5-4968-b8cb-1e4b2743a632","metadata":{"id":"ef7bb34f-6ac5-4968-b8cb-1e4b2743a632"},"outputs":[],"source":["# 모델 저장 (전체 모델 저장 추가)\n","torch.save(model, \"./best_model.pth\")"]},{"cell_type":"code","execution_count":null,"id":"b8541175-73fc-4c25-af39-475b74126b1f","metadata":{"scrolled":true,"id":"b8541175-73fc-4c25-af39-475b74126b1f","outputId":"b153da3a-42e3-4c6b-a124-db6c5d0fc211"},"outputs":[{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","\n","# 저장된 모델 로드\n","model = torch.load(\"./best_model.pth\")\n","model.eval()  # 평가 모드로 변경"]},{"cell_type":"code","execution_count":null,"id":"4cf96631-1c77-44a5-ab06-a2569acf6273","metadata":{"id":"4cf96631-1c77-44a5-ab06-a2569acf6273","outputId":"da5b7b79-1d2b-481a-e740-9e45545559f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["예측 확률: tensor([[0.9967, 0.0074, 0.9976, 0.0036, 0.0024, 0.0031]], device='cuda:0')\n","예측 결과 (0=해당 없음, 1=해당): [[1 0 1 0 0 0]]\n"]}],"source":["from transformers import BertTokenizer\n","import torch\n","\n","# BERT 토크나이저 로드\n","tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")\n","\n","# 새로운 리뷰 예제\n","text = \"이 제품은 가성비가 뛰어나고 디자인이 정말 멋져요!\"\n","inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n","\n","# GPU 사용 가능하면 모델도 GPU로 이동\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","inputs = {key: val.to(device) for key, val in inputs.items()}\n","\n","# 모델 예측 실행\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","\n","# 로짓을 확률로 변환\n","probs = torch.sigmoid(outputs.logits)\n","predictions = (probs > 0.5).int()  # 0.5 이상이면 해당 클래스로 예측\n","\n","print(\"예측 확률:\", probs)\n","print(\"예측 결과 (0=해당 없음, 1=해당):\", predictions.cpu().numpy())"]},{"cell_type":"code","execution_count":null,"id":"425a7b40-fc7f-4a1a-9af4-41819711dc58","metadata":{"id":"425a7b40-fc7f-4a1a-9af4-41819711dc58","outputId":"f8bd171c-d62a-4256-b2eb-a7928285e6dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["📝 리뷰 1: 가격 대비 품질이 뛰어나고 디자인도 세련됐어요. 정말 만족합니다.\n","🔹 예측된 라벨: ['가성비', '내구성 및 품질', '디자인']\n","--------------------------------------------------------------------------------\n","📝 리뷰 2: 신발이 튼튼하고 내구성이 좋아서 오래 신을 수 있을 것 같아요.\n","🔹 예측된 라벨: ['내구성 및 품질']\n","--------------------------------------------------------------------------------\n","📝 리뷰 3: 배송이 예상보다 빨랐고, 포장도 꼼꼼하게 잘 되어 있었어요.\n","🔹 예측된 라벨: ['배송 및 포장 및 응대']\n","--------------------------------------------------------------------------------\n","📝 리뷰 4: 사이즈가 딱 맞고 착화감이 편해서 장시간 신어도 문제 없어요.\n","🔹 예측된 라벨: ['사이즈', '착용감']\n","--------------------------------------------------------------------------------\n","📝 리뷰 5: 디자인이 너무 예쁘고 색감도 고급스러워요. 선물하기에도 좋아요.\n","🔹 예측된 라벨: ['디자인']\n","--------------------------------------------------------------------------------\n","📝 리뷰 6: 가격이 너무 비싼데 품질은 기대 이하여서 아쉬웠어요.\n","🔹 예측된 라벨: ['가성비', '내구성 및 품질']\n","--------------------------------------------------------------------------------\n","📝 리뷰 7: 조금만 신었는데 벌써 해지기 시작했어요. 내구성이 너무 약하네요.\n","🔹 예측된 라벨: ['내구성 및 품질']\n","--------------------------------------------------------------------------------\n","📝 리뷰 8: 배송이 너무 늦고, 상자도 찌그러져서 왔어요. 기분이 별로네요.\n","🔹 예측된 라벨: ['배송 및 포장 및 응대']\n","--------------------------------------------------------------------------------\n","📝 리뷰 9: 사이즈가 설명과 다르게 작게 나와서 불편합니다. 교환해야 할 듯.\n","🔹 예측된 라벨: ['사이즈', '착용감']\n","--------------------------------------------------------------------------------\n","📝 리뷰 10: 사진이랑 색상이 너무 다르게 나와서 실망했어요. 디자인이 별로네요.\n","🔹 예측된 라벨: ['디자인']\n","--------------------------------------------------------------------------------\n"]}],"source":["from transformers import BertTokenizer\n","import torch\n","\n","# BERT 토크나이저 로드\n","tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")\n","\n","# 모델을 GPU로 이동\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()  # 평가 모드\n","\n","# 6개 클래스 레이블 정의\n","class_labels = [\"가성비\", \"내구성 및 품질\", \"디자인\", \"배송 및 포장 및 응대\", \"사이즈\", \"착용감\"]\n","\n","# 10개 샘플 리뷰\n","test_samples = [\n","    \"가격 대비 품질이 뛰어나고 디자인도 세련됐어요. 정말 만족합니다.\",\n","    \"신발이 튼튼하고 내구성이 좋아서 오래 신을 수 있을 것 같아요.\",\n","    \"배송이 예상보다 빨랐고, 포장도 꼼꼼하게 잘 되어 있었어요.\",\n","    \"사이즈가 딱 맞고 착화감이 편해서 장시간 신어도 문제 없어요.\",\n","    \"디자인이 너무 예쁘고 색감도 고급스러워요. 선물하기에도 좋아요.\",\n","    \"가격이 너무 비싼데 품질은 기대 이하여서 아쉬웠어요.\",\n","    \"조금만 신었는데 벌써 해지기 시작했어요. 내구성이 너무 약하네요.\",\n","    \"배송이 너무 늦고, 상자도 찌그러져서 왔어요. 기분이 별로네요.\",\n","    \"사이즈가 설명과 다르게 작게 나와서 불편합니다. 교환해야 할 듯.\",\n","    \"사진이랑 색상이 너무 다르게 나와서 실망했어요. 디자인이 별로네요.\"\n","]\n","\n","# 예측 수행 함수\n","def predict_review(texts):\n","    inputs = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n","    inputs = {key: val.to(device) for key, val in inputs.items()}\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    probs = torch.sigmoid(outputs.logits)  # 확률 변환\n","    predictions = (probs > 0.5).int()  # 0.5 이상이면 해당 클래스로 예측\n","\n","    return probs.cpu().numpy(), predictions.cpu().numpy()\n","\n","# 10개 샘플 예측\n","probs, preds = predict_review(test_samples)\n","\n","# 결과 출력\n","for i, (review, prob, pred) in enumerate(zip(test_samples, probs, preds)):\n","    predicted_labels = [class_labels[j] for j in range(len(class_labels)) if pred[j] == 1]  # 1인 레이블만 선택\n","\n","    print(f\"📝 리뷰 {i+1}: {review}\")\n","    print(f\"🔹 예측된 라벨: {predicted_labels if predicted_labels else ['해당 없음']}\")\n","    print(\"-\" * 80)\n"]}],"metadata":{"kernelspec":{"display_name":"Python (pytorch_env)","language":"python","name":"pytorch_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.21"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}