import os
import re
import pymysql
import torch
import kss
from datetime import datetime
from transformers import BertTokenizer, BertForSequenceClassification, AutoTokenizer, AutoModelForSequenceClassification

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ëª¨ë¸
category_model_path = "/home/lab01/airflow/model/best_model.pth"
sentiment_model_path = "/home/lab01/airflow/model/best_model_with_val.pth"

try:
    # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ëª¨ë¸ (`klue/bert-base`)
    print("[INFO] ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    category_tokenizer = BertTokenizer.from_pretrained("klue/bert-base")
    category_model = BertForSequenceClassification.from_pretrained("klue/bert-base", num_labels=6)

    # ëª¨ë¸ ì €ì¥ ë°©ì‹ í™•ì¸ í›„ ë¡œë“œ
    category_model_data = torch.load(category_model_path, map_location=device)
    if isinstance(category_model_data, dict):
        category_model.load_state_dict(category_model_data)
    else:
        category_model = category_model_data  # ì „ì²´ ëª¨ë¸ ì €ì¥ëœ ê²½ìš°

    category_model.to(device)
    category_model.eval()
    print("[INFO] ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # ê°ì„± ë¶„ì„ ëª¨ë¸ (`monologg/kobert`)
    print("[INFO] ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    sentiment_tokenizer = AutoTokenizer.from_pretrained("monologg/kobert", trust_remote_code=True)
    sentiment_model_data = torch.load(sentiment_model_path, map_location=device)
    
    # ëª¨ë¸ ì €ì¥ ë°©ì‹ í™•ì¸ í›„ ë¡œë“œ
    if isinstance(sentiment_model_data, dict):
        sentiment_model = AutoModelForSequenceClassification.from_pretrained(
            "monologg/kobert",
            num_labels=3,
            trust_remote_code=True  # ì‹ ë¢° ì½”ë“œ ì‹¤í–‰ ì˜µì…˜ ì¶”ê°€
        )
        sentiment_model.load_state_dict(sentiment_model_data, strict=False)  # ğŸ”¹ strict=False ì˜µì…˜ ì¶”ê°€
    else:
        sentiment_model = sentiment_model_data  # ì „ì²´ ëª¨ë¸ ì €ì¥ëœ ê²½ìš°
    
    sentiment_model.to(device)
    sentiment_model.eval()
    print("[INFO] ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

except Exception as e:
    print(f"[ERROR] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit(1)

# ì¹´í…Œê³ ë¦¬ ëª©ë¡
CATEGORIES = ["ê°€ì„±ë¹„", "ë‚´êµ¬ì„± ë° í’ˆì§ˆ", "ë””ìì¸", "ë°°ì†¡ ë° í¬ì¥ ë° ì‘ëŒ€", "ì‚¬ì´ì¦ˆ", "ì°©ìš©ê°"]

# ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸
stopwords = set([
    "ì•„", "íœ´", "ì•„ì´êµ¬", "ì•„ì´ì¿ ", "ì•„ì´ê³ ", "ì–´", "ë‚˜", "ìš°ë¦¬", "ì €í¬", "ë”°ë¼", "ì˜í•´", "ì„", "ë¥¼", "ì—", "ì˜", "ê°€", "ìœ¼ë¡œ", "ë¡œ", "ì—ê²Œ",
    "ë¿ì´ë‹¤", "ì˜ê±°í•˜ì—¬", "ê·¼ê±°í•˜ì—¬", "ì…ê°í•˜ì—¬", "ê¸°ì¤€ìœ¼ë¡œ", "ì˜ˆí•˜ë©´", "ì˜ˆë¥¼ ë“¤ë©´", "ì˜ˆë¥¼ ë“¤ìë©´", "ì €", "ì†Œì¸", "ì†Œìƒ", "ì €í¬", "ì§€ë§ê³ ",
    "í•˜ì§€ë§ˆ", "í•˜ì§€ë§ˆë¼", "ë‹¤ë¥¸", "ë¬¼ë¡ ", "ë˜í•œ", "ê·¸ë¦¬ê³ ", "ë¹„ê¸¸ìˆ˜ ì—†ë‹¤", "í•´ì„œëŠ” ì•ˆëœë‹¤", "ë¿ë§Œ ì•„ë‹ˆë¼", "ë§Œì´ ì•„ë‹ˆë‹¤", "ë§Œì€ ì•„ë‹ˆë‹¤", "ë§‰ë¡ í•˜ê³ ",
    "ê´€ê³„ì—†ì´", "ê·¸ì¹˜ì§€ ì•Šë‹¤", "ê·¸ëŸ¬ë‚˜", "ê·¸ëŸ°ë°", "í•˜ì§€ë§Œ", "ë“ ê°„ì—", "ë…¼í•˜ì§€ ì•Šë‹¤", "ë”°ì§€ì§€ ì•Šë‹¤", "ì„¤ì‚¬", "ë¹„ë¡", "ë”ë¼ë„", "ì•„ë‹ˆë©´", "ë§Œ ëª»í•˜ë‹¤",
    "í•˜ëŠ” í¸ì´ ë‚«ë‹¤", "ë¶ˆë¬¸í•˜ê³ ", "í–¥í•˜ì—¬", "í–¥í•´ì„œ", "í–¥í•˜ë‹¤", "ìª½ìœ¼ë¡œ", "í‹ˆíƒ€", "ì´ìš©í•˜ì—¬", "íƒ€ë‹¤", "ì˜¤ë¥´ë‹¤", "ì œì™¸í•˜ê³ ", "ì´ ì™¸ì—", "ì´ ë°–ì—",
    "í•˜ì—¬ì•¼", "ë¹„ë¡œì†Œ", "í•œë‹¤ë©´ ëª°ë¼ë„", "ì™¸ì—ë„", "ì´ê³³", "ì—¬ê¸°", "ë¶€í„°", "ê¸°ì ìœ¼ë¡œ", "ë”°ë¼ì„œ", "í•  ìƒê°ì´ë‹¤", "í•˜ë ¤ê³ í•˜ë‹¤", "ì´ë¦¬í•˜ì—¬", "ê·¸ë¦¬í•˜ì—¬",
    "ê·¸ë ‡ê²Œ í•¨ìœ¼ë¡œì¨", "í•˜ì§€ë§Œ", "ì¼ë•Œ", "í• ë•Œ", "ì•ì—ì„œ", "ì¤‘ì—ì„œ", "ë³´ëŠ”ë°ì„œ", "ìœ¼ë¡œì¨", "ë¡œì¨", "ê¹Œì§€", "í•´ì•¼í•œë‹¤", "ì¼ê²ƒì´ë‹¤", "ë°˜ë“œì‹œ",
    "í• ì¤„ì•Œë‹¤", "í• ìˆ˜ìˆë‹¤", "í• ìˆ˜ìˆì–´", "ì„ì— í‹€ë¦¼ì—†ë‹¤", "í•œë‹¤ë©´", "ë“±", "ë“±ë“±", "ì œ", "ê²¨ìš°", "ë‹¨ì§€", "ë‹¤ë§Œ", "í• ë¿", "ë”©ë™", "ëŒ•ê·¸", "ëŒ€í•´ì„œ",
    "ëŒ€í•˜ì—¬", "ëŒ€í•˜ë©´", "í›¨ì”¬", "ì–¼ë§ˆë‚˜", "ì–¼ë§ˆë§Œí¼", "ì–¼ë§ˆí¼", "ë‚¨ì§“", "ì—¬", "ì–¼ë§ˆê°„", "ì•½ê°„", "ë‹¤ì†Œ", "ì¢€", "ì¡°ê¸ˆ", "ë‹¤ìˆ˜", "ëª‡", "ì–¼ë§ˆ",
    "ì§€ë§Œ", "í•˜ë¬¼ë©°", "ë˜í•œ", "ê·¸ëŸ¬ë‚˜", "ê·¸ë ‡ì§€ë§Œ", "í•˜ì§€ë§Œ", "ì´ì™¸ì—ë„", "ëŒ€í•´ ë§í•˜ìë©´", "ë¿ì´ë‹¤", "ë‹¤ìŒì—", "ë°˜ëŒ€ë¡œ", "ë°˜ëŒ€ë¡œ ë§í•˜ìë©´",
    "ì´ì™€ ë°˜ëŒ€ë¡œ", "ë°”ê¾¸ì–´ì„œ ë§í•˜ë©´", "ë°”ê¾¸ì–´ì„œ í•œë‹¤ë©´", "ë§Œì•½", "ê·¸ë ‡ì§€ì•Šìœ¼ë©´", "ê¹Œì•…", "íˆ­", "ë”±", "ì‚ê±±ê±°ë¦¬ë‹¤", "ë³´ë“œë“", "ë¹„ê±±ê±°ë¦¬ë‹¤", "ê½ˆë‹¹",
    "ì‘ë‹¹", "í•´ì•¼í•œë‹¤", "ì— ê°€ì„œ", "ê°", "ê°ê°", "ì—¬ëŸ¬ë¶„", "ê°ì¢…", "ê°ì", "ì œê°ê¸°", "í•˜ë„ë¡í•˜ë‹¤", "ì™€", "ê³¼", "ê·¸ëŸ¬ë¯€ë¡œ", "ê·¸ë˜ì„œ", "ê³ ë¡œ",
    "í•œ ê¹Œë‹­ì—", "í•˜ê¸° ë•Œë¬¸ì—", "ê±°ë‹ˆì™€", "ì´ì§€ë§Œ", "ëŒ€í•˜ì—¬", "ê´€í•˜ì—¬", "ê´€í•œ", "ê³¼ì—°", "ì‹¤ë¡œ", "ì•„ë‹ˆë‚˜ë‹¤ë¥¼ê°€", "ìƒê°í•œëŒ€ë¡œ", "ì§„ì§œë¡œ", "í•œì ì´ìˆë‹¤",
    "í•˜ê³¤í•˜ì˜€ë‹¤", "í•˜", "í•˜í•˜", "í—ˆí—ˆ", "ì•„í•˜", "ê±°ë°”", "ì™€", "ì˜¤", "ì™œ", "ì–´ì§¸ì„œ", "ë¬´ì—‡ë•Œë¬¸ì—", "ì–´ì°Œ", "í•˜ê² ëŠ”ê°€", "ë¬´ìŠ¨", "ì–´ë””", "ì–´ëŠê³³",
    "ë”êµ°ë‹¤ë‚˜", "í•˜ë¬¼ë©°", "ë”ìš±ì´ëŠ”", "ì–´ëŠë•Œ", "ì–¸ì œ", "ì•¼", "ì´ë´", "ì–´ì´", "ì—¬ë³´ì‹œì˜¤", "íí", "í¥", "íœ´", "í—‰í—‰", "í—ë–¡í—ë–¡", "ì˜ì°¨", "ì—¬ì°¨",
    "ì–´ê¸°ì—¬ì°¨", "ë™ë™", "ì•„ì•¼", "ì•—", "ì•„ì•¼", "ì½¸ì½¸", "ì¡¸ì¡¸", "ì¢ì¢", "ëšëš", "ì£¼ë£©ì£¼ë£©", "ì†¨", "ìš°ë¥´ë¥´", "ê·¸ë˜ë„", "ë˜", "ê·¸ë¦¬ê³ ", "ë°”ê¾¸ì–´ë§í•˜ë©´",
    "ë°”ê¾¸ì–´ë§í•˜ìë©´", "í˜¹ì€", "í˜¹ì‹œ", "ë‹µë‹¤", "ë°", "ê·¸ì— ë”°ë¥´ëŠ”", "ë•Œê°€ ë˜ì–´", "ì¦‰", "ì§€ë“ ì§€", "ì„¤ë ¹", "ê°€ë ¹", "í•˜ë”ë¼ë„", "í• ì§€ë¼ë„", "ì¼ì§€ë¼ë„",
    "ì§€ë“ ì§€", "ëª‡", "ê±°ì˜", "í•˜ë§ˆí„°ë©´", "ì¸ì  ", "ì´ì  ", "ëœë°”ì—ì•¼", "ëœì´ìƒ", "ë§Œí¼", "ì–´ì°Œëë“ ", "ê·¸ìœ„ì—", "ê²Œë‹¤ê°€", "ì ì—ì„œ ë³´ì•„", "ë¹„ì¶”ì–´ ë³´ì•„",
    "ê³ ë ¤í•˜ë©´", "í•˜ê²Œë ê²ƒì´ë‹¤", "ì¼ê²ƒì´ë‹¤", "ë¹„êµì ", "ì¢€", "ë³´ë‹¤ë”", "ë¹„í•˜ë©´", "ì‹œí‚¤ë‹¤", "í•˜ê²Œí•˜ë‹¤", "í• ë§Œí•˜ë‹¤", "ì˜í•´ì„œ", "ì—°ì´ì„œ", "ì´ì–´ì„œ",
    "ì‡ë”°ë¼", "ë’¤ë”°ë¼", "ë’¤ì´ì–´", "ê²°êµ­", "ì˜ì§€í•˜ì—¬", "ê¸°ëŒ€ì—¬", "í†µí•˜ì—¬", "ìë§ˆì", "ë”ìš±ë”", "ë¶ˆêµ¬í•˜ê³ ", "ì–¼ë§ˆë“ ì§€", "ë§ˆìŒëŒ€ë¡œ", "ì£¼ì €í•˜ì§€ ì•Šê³ ",
    "ê³§", "ì¦‰ì‹œ", "ë°”ë¡œ", "ë‹¹ì¥", "í•˜ìë§ˆì", "ë°–ì— ì•ˆëœë‹¤", "í•˜ë©´ëœë‹¤", "ê·¸ë˜", "ê·¸ë ‡ì§€", "ìš”ì»¨ëŒ€", "ë‹¤ì‹œ ë§í•˜ìë©´", "ë°”ê¿” ë§í•˜ë©´", "ì¦‰", "êµ¬ì²´ì ìœ¼ë¡œ", 
    'ë„ˆë¬´', 'ë”ë³´ê¸°', 'íˆíˆ', 'í¬í¬', 'ì¼€ì¼€', 'ê·¸ëƒ¥', 'ì‰', 'ì•™', 'ì—‰', 'ì˜¹', 'í•˜', 'ì•¼', 'ì´ì•¼'
])

# MySQL ì—°ê²° ì •ë³´
DB_CONFIG = {
    "host": "15.152.242.221",
    "user": "admin",
    "password": "Admin@1234",
    "database": "musinsa_pd_rv"
}

# ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
def reset_table():
    try:
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()
        TODAY = datetime.today().strftime("%Y%m%d")
        TABLE_NAME = f"today_reviews_{TODAY}_analysis"

        cursor.execute(f"DROP TABLE IF EXISTS {TABLE_NAME}")
        conn.commit()
        print(f"[INFO] ê¸°ì¡´ ë¶„ì„ í…Œì´ë¸” ì‚­ì œ ì™„ë£Œ: {TABLE_NAME}")

        cursor.close()
        conn.close()
    except Exception as e:
        print(f"[ERROR] í…Œì´ë¸” ì‚­ì œ ì‹¤íŒ¨: {e}")
        exit(1)

# ë¦¬ë·° ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
def get_new_reviews():
    try:
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()
        TODAY = datetime.today().strftime("%Y-%m-%d")

        query = f"""
        SELECT review_id, product_id, review_text, review_date, rating
        FROM reviews WHERE review_date = '{TODAY}'
        """
        cursor.execute(query)
        reviews = cursor.fetchall()

        cursor.close()
        conn.close()
        print(f"[INFO] {len(reviews)}ê°œì˜ ë¦¬ë·° ë°ì´í„°ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
        return reviews
    except Exception as e:
        print(f"[ERROR] MySQL ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        exit(1)

# í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜
def clean_text(text):
    text = str(text)

    # ã…‹ã…‹ã…‹, ã…ã…ã…, ã… ã… ã…  ê°™ì€ ê°íƒ„ì‚¬ ì œê±°
    text = re.sub(r"ã…‹{2,}|ã…{2,}|ã… {2,}|ã…œ{2,}", "", text)
    
    # í•œê¸€ ë° ê³µë°±ë§Œ ë‚¨ê¸°ê³  ì œê±°
    text = re.sub(r"[^ê°€-í£\s]", "", text)
    
    # ë¶ˆìš©ì–´ ì œê±°
    words = text.split()
    words = [word for word in words if word not in stopwords]
    
    # ì •ì œëœ ë‹¨ì–´ë“¤ì„ ë‹¤ì‹œ í•©ì¹¨
    text = " ".join(words)
    
    # ê³µë°± ì •ë¦¬
    text = re.sub(r"\s+", " ", text).strip()
    
    return text

# ë¬¸ì¥ ë¶„ë¦¬
def split_sentences(review):
    return kss.split_sentences(review)

# ë¦¬ë·° ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡ (ë‹¤ì¤‘ ë¼ë²¨ ë¶„ë¥˜)
def predict_category(sentence):
    inputs = category_tokenizer(sentence, padding="max_length", truncation=True, max_length=128, return_tensors="pt").to(device)

    with torch.no_grad():
        outputs = category_model(**inputs)

    probs = torch.sigmoid(outputs.logits)
    predictions = (probs > 0.5).int()

    predicted_labels = [CATEGORIES[j] for j in range(len(CATEGORIES)) if predictions[0][j] == 1]
    
    return predicted_labels if predicted_labels else ["ê¸°íƒ€"]

# ê°ì„± ë¶„ì„ ì˜ˆì¸¡ (ë¶€ì •=0, ì¤‘ë¦½=1, ê¸ì •=2)
def predict_sentiment(sentence):
    inputs = sentiment_tokenizer(sentence, padding="max_length", truncation=True, max_length=128, return_tensors="pt").to(device)

    with torch.no_grad():
        outputs = sentiment_model(**inputs)

    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    sentiment_class = torch.argmax(probs, dim=-1).item()  #0: ë¶€ì •, 1: ì¤‘ë¦½, 2: ê¸ì •
    
    # ê°ì„± ë¶„ì„ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•  ìˆ˜ë„ ìˆìŒ
    sentiment_labels = {0: "ë¶€ì •", 1: "ì¤‘ë¦½", 2: "ê¸ì •"}
    return sentiment_class  # ë˜ëŠ” sentiment_labels[sentiment_class]ë¡œ ë°˜í™˜ ê°€ëŠ¥


# ë¶„ì„ ê²°ê³¼ ì €ì¥
def save_results_to_mysql(results):
    try:
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()
        TODAY = datetime.today().strftime("%Y%m%d")
        TABLE_NAME = f"today_reviews_{TODAY}_analysis"

        # âœ… `today_reviews_{TODAY}_analysis` í…Œì´ë¸” ìƒì„± (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        create_table_query = f"""
        CREATE TABLE IF NOT EXISTS {TABLE_NAME} (
            review_id VARCHAR(255),
            product_id VARCHAR(255),
            sentence VARCHAR(255),
            category VARCHAR(255),
            sentiment INT,
            rating FLOAT,
            review_date DATE,
            PRIMARY KEY (review_id, sentence)
        );
        """
        cursor.execute(create_table_query)
        conn.commit()

        # âœ… `review_analysis` í…Œì´ë¸”ì—ë„ ë™ì¼í•œ êµ¬ì¡°ë¡œ ì €ì¥
        create_table_query_review_analysis = """
        CREATE TABLE IF NOT EXISTS review_analysis (
            review_id VARCHAR(100),
            product_id VARCHAR(50),
            sentence TEXT,
            category VARCHAR(255),
            sentiment INT,
            rating FLOAT,
            review_date DATE,
            PRIMARY KEY (review_id, category)
        );
        """
        cursor.execute(create_table_query_review_analysis)
        conn.commit()

        # âœ… `today_reviews_{TODAY}_analysis` í…Œì´ë¸”ì— ë°ì´í„° ì €ì¥
        insert_query_today = f"""
        INSERT INTO {TABLE_NAME} (review_id, product_id, sentence, category, sentiment, rating, review_date)
        VALUES (%s, %s, %s, %s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE category = VALUES(category), sentiment = VALUES(sentiment);
        """
        cursor.executemany(insert_query_today, results)
        conn.commit()
        print(f"[INFO] {len(results)}ê°œì˜ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ ({TABLE_NAME})")

        # âœ… `review_analysis` í…Œì´ë¸”ì—ë„ ë™ì¼í•œ ë°ì´í„° ì‚½ì…
        insert_query_review_analysis = """
        INSERT INTO review_analysis (review_id, product_id, sentence, category, sentiment, rating, review_date)
        VALUES (%s, %s, %s, %s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE category = VALUES(category), sentiment = VALUES(sentiment);
        """
        cursor.executemany(insert_query_review_analysis, results)
        conn.commit()
        print(f"[INFO] {len(results)}ê°œì˜ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ (review_analysis)")

        cursor.close()
        conn.close()
    except Exception as e:
        print(f"[ERROR] MySQL ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        exit(1)

# ì‹¤í–‰
if __name__ == "__main__":
    reset_table()
    new_reviews = get_new_reviews()

    if new_reviews:
        results = []
        for review_id, product_id, review_text, review_date, rating in new_reviews:
            cleaned_text = clean_text(review_text)
            for sentence in split_sentences(cleaned_text):
                categories = predict_category(sentence)
                sentiment = predict_sentiment(sentence)

                results.append((review_id, product_id, sentence[:255], ",".join(categories), sentiment, rating, review_date))

        save_results_to_mysql(results)
